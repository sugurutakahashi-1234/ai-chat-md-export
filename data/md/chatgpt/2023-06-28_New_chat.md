# New chat

æ—¥ä»˜: 2023-06-28

---

## ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼
*2023/6/29 8:51:38*

æƒ³åƒã§ã„ã„ã®ã§ã€å˜æ•°ç³»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å‡¦ç†ã‚‚æ›¸ã„ã¦ã¿ã¦æ¬²ã—ã„
static func analyzeEmotion(sampleBufferAndTimestamp: (sampleBuffer: CMSampleBuffer, timestampInMilliseconds: Double), isEnableSavingImageForDebug: Bool = false) async throws -&gt; [EmotionDataModel]

private extension AnchorAndEmotionAnalysisInteractor {
    // ã“ã® func ã®å‡¦ç†ãŒ class ã§ä¿æŒã—ã¦ã„ã‚‹å¤‰æ•°ã«ã‚ˆã‚‰ãªã„ã“ã¨ã‚’æ˜ç¤ºçš„ã«ã™ã‚‹ãŸã‚ã« static func ã¨ã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã‚‚ã—ãƒ¡ãƒ¢ãƒªå•é¡Œã«ãªã£ãŸå ´åˆã§ã‚‚ã€åˆ†å‰²ã—ã¦å‡¦ç†ãŒè¡Œãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã¾ãŸã€ãƒ†ã‚¹ãƒˆã‚‚å®¹æ˜“ã«ãªã‚‹ã€‚
    static func analyzeEmotion(sampleBufferAndTimestamps: [(sampleBuffer: CMSampleBuffer, timestampInMilliseconds: Double)], isEnableSavingImageForDebug: Bool = false) async throws -&gt; [EmotionDataModel] {
        var emotionPredictionResults: [EmotionPredictionResult] = []

        try await withThrowingTaskGroup(of: EmotionPredictionResult.self) { group in
            for (sampleBuffer, timestampInMilliseconds) in sampleBufferAndTimestamps {
                group.addTask {
                    let imageItem = try await EmotionAnalysis.predictWithFaceDetection(sampleBuffer: sampleBuffer, timestamp: timestampInMilliseconds)
                    return EmotionPredictionResult(timestampInMilliseconds: timestampInMilliseconds, imageItem: imageItem)
                }
            }

            for try await result in group {
                emotionPredictionResults.append(result)
            }
        }

        if isEnableSavingImageForDebug {
            try emotionPredictionResults.flatMap(\.imageItem).forEach {
                try Self.saveImageToDocumentDirectory(imageItem: $0)
            }
        }

        return emotionPredictionResults.flatMap { emotionPredictionResult -&gt; [EmotionDataModel] in
            emotionPredictionResult.emotionDataModels
        }
    }
}

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2023/6/29 8:52:10*

ã™ã§ã«ä¸ãˆã‚‰ã‚ŒãŸ `analyzeEmotion` ãƒ¡ã‚½ãƒƒãƒ‰ã¯è¤‡æ•°ã®ãƒãƒƒãƒ•ã‚¡ã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚‰ã‚’éåŒæœŸã«å‡¦ç†ã—ã¦çµæœã‚’è¿”ã™ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚å˜æ•°ã®ãƒãƒƒãƒ•ã‚¡ã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ‰±ã†ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚åŒæ§˜ã«éåŒæœŸã§å®Ÿè£…ã§ãã¾ã™ã€‚ä»¥ä¸‹ã«ãã®ã‚ˆã†ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã® `analyzeEmotion` ã‚’ç¤ºã—ã¾ã™ï¼š

```swift
static func analyzeEmotion(sampleBufferAndTimestamp: (sampleBuffer: CMSampleBuffer, timestampInMilliseconds: Double), isEnableSavingImageForDebug: Bool = false) async throws -> EmotionDataModel {
    let (sampleBuffer, timestampInMilliseconds) = sampleBufferAndTimestamp

    let emotionPredictionResult = try await withThrowingTask { 
        let imageItem = try await EmotionAnalysis.predictWithFaceDetection(sampleBuffer: sampleBuffer, timestamp: timestampInMilliseconds)
        return EmotionPredictionResult(timestampInMilliseconds: timestampInMilliseconds, imageItem: imageItem)
    }

    if isEnableSavingImageForDebug, let imageItem = emotionPredictionResult.imageItem {
        try Self.saveImageToDocumentDirectory(imageItem: $0)
    }

    return emotionPredictionResult.emotionDataModels
}
```

ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€å˜æ•°ã®ãƒãƒƒãƒ•ã‚¡ã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å¼•æ•°ã«å–ã‚Šã€åŒæ§˜ã«éåŒæœŸã«ãã‚Œã‚’å‡¦ç†ã—ã¾ã™ã€‚ãŸã ã—ã€ã“ã‚Œã¯ `EmotionDataModel` ã®å˜æ•°å½¢ã‚’è¿”ã—ã¾ã™ã€‚ã¾ãŸã€ãƒ‡ãƒãƒƒã‚°ç”¨ã®ç”»åƒã®ä¿å­˜ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹å ´åˆã€çµæœã®ç”»åƒé …ç›®ãŒå­˜åœ¨ã™ã‚‹ã¨ãã ã‘ãã‚Œã‚’ä¿å­˜ã—ã¾ã™ã€‚

ãŸã ã—ã€ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã¯ã€å…ƒã®ã‚³ãƒ¼ãƒ‰ãŒ `EmotionDataModels` ã‚’è¤‡æ•°è¿”ã™ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚å˜ä¸€ã® `EmotionDataModel` ãŒè¿”ã•ã‚Œã‚‹ã¹ãå ´åˆã¯ã€ `emotionPredictionResult.emotionDataModels` ã®éƒ¨åˆ†ã‚’é©åˆ‡ã«èª¿æ•´ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€ã“ã®é–¢æ•°ã®æˆ»ã‚Šå€¤ã®å‹ãŒ `EmotionDataModel` ã®é…åˆ—ã§ãªã `EmotionDataModel` å˜ä½“ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

---
