# 音声入力設定指南

日付: 2024-05-07

---

## 👤 ユーザー
*2024/5/7 9:54:58*

iOSアプリでマイクからの音声入力をさせたい。
やらなければならない設定を教えてほしい

---

## 🤖 アシスタント
*2024/5/7 9:55:42*

iOSアプリでマイクからの音声入力を利用するには、以下の手順に従って設定を行う必要があります。

1. **プライバシー設定の追加**:
   iOSはプライバシーを重視しているため、アプリがユーザーのマイクを使用する場合、事前にユーザーの許可を得る必要があります。`Info.plist`ファイルに`NSMicrophoneUsageDescription`キーを追加し、マイクアクセスの目的を説明するメッセージを設定します。

   ```xml
   <key>NSMicrophoneUsageDescription</key>
   <string>このアプリは、音声認識のためにマイクのアクセスが必要です。</string>
   ```

2. **マイクアクセスの許可を求める**:
   アプリ内で`AVFoundation`フレームワークを使用して、マイクアクセスの許可をユーザーに求めます。例えば、`AVAudioSession`を使って、マイクの使用許可をプログラム的に要求することができます。

   ```swift
   import AVFoundation

   func requestMicrophoneAccess() {
       switch AVAudioSession.sharedInstance().recordPermission {
       case .granted:
           // 許可済みの場合
           break
       case .denied:
           // ユーザーに拒否された場合
           break
       case .undetermined:
           // まだユーザーに尋ねていない場合
           AVAudioSession.sharedInstance().requestRecordPermission { granted in
               if granted {
                   // 許可された場合
               } else {
                   // 許可されなかった場合
               }
           }
       default:
           break
       }
   }
   ```

3. **オーディオセッションの設定**:
   マイクからの入力を受け取るためには、適切なオーディオセッションカテゴリを設定する必要があります。通常、`playAndRecord`カテゴリが使用されます。

   ```swift
   func setupAudioSession() {
       do {
           try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default)
           try AVAudioSession.sharedInstance().setActive(true)
       } catch {
           print("Failed to set audio session category. \(error)")
       }
   }
   ```

これらの設定を行った後、マイクからの音声データを受け取るためのコードを実装することができます。これには、`AVAudioRecorder`を使用するか、リアルタイムで音声を処理する場合は`AVAudioEngine`を使用するなどがあります。それぞれのケースに合わせて実装を進めてください。

---

## 👤 ユーザー
*2024/5/7 10:51:21*

録音しようとしたら、AddInstanceForFactory: No factory registered for id &lt;CFUUID 0x6000002ceea0&gt; F8BB1C28-BAE8-11D6-9C31-00039315CD46というエラーになった

---

## 🤖 アシスタント
*2024/5/7 10:52:23*

このエラーメッセージ `AddInstanceForFactory: No factory registered for id <CFUUID 0x6000002ceea0> F8BB1C28-BAE8-11D6-9C31-00039315CD46` は、オーディオセッションの設定が適切に行われていないか、何かが正しく初期化されていない場合に発生することがあります。以下のステップで問題を解決できるかもしれません。

1. **オーディオセッションの設定確認**:
   - アプリがオーディオセッションを適切に設定しているか確認してください。特に、`setCategory` と `setActive` の呼び出しが正しいかどうかを確認します。

2. **シミュレーターではなく実機でテスト**:
   - iOSのオーディオ関連の機能はシミュレーターでは限定的です。実機でのテストを行うことで、問題が解決する可能性があります。

3. **プロジェクトのクリーンとビルド**:
   - Xcodeでプロジェクトをクリーンしてから再ビルドを試みてください。キャッシュが原因で起きる問題を解消できることがあります。

4. **オーディオハードウェアの確認**:
   - 使用しているデバイスのオーディオ入力が正常に機能しているかを確認してください。

5. **最小限のコードでのテスト**:
   - 新しいプロジェクトを作成して、最小限のコードでマイク入力をテストすることで、問題がコードに由来するのか、環境に問題があるのかを判断できます。

ここに簡単なオーディオレコーディングのセットアップ例を示します。このコードを新しいプロジェクトで試してみてください。

```swift
import AVFoundation

class AudioRecorder {

    var audioRecorder: AVAudioRecorder?

    func setupAudioSession() {
        do {
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default)
            try AVAudioSession.sharedInstance().setActive(true)
            startRecording()
        } catch {
            print("Failed to set audio session category. \(error)")
        }
    }

    func startRecording() {
        let audioFilename = getDocumentsDirectory().appendingPathComponent("recording.m4a")

        let settings = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 12000,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]

        do {
            audioRecorder = try AVAudioRecorder(url: audioFilename, settings: settings)
            audioRecorder?.record()
        } catch {
            print("Could not start recording: \(error)")
        }
    }

    func getDocumentsDirectory() -> URL {
        let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
        return paths[0]
    }
}
```

このクラスを使用すると、オーディオセッションを設定し、簡単なレコーディングを開始できます。エラーが発生する場合は、提供されたエラーメッセージを基にさらにトラブルシューティングを行ってください。

---

## 👤 ユーザー
*2024/5/7 10:55:06*

stop レコード処理を書いてほしい

---

## 🤖 アシスタント
*2024/5/7 10:55:46*

レコーディングを停止するための処理を追加するには、`AVAudioRecorder` の `stop` メソッドを呼び出す必要があります。以下に、先ほどのクラスにレコーディングを停止するメソッドを追加した例を示します。

```swift
import AVFoundation

class AudioRecorder {

    var audioRecorder: AVAudioRecorder?

    func setupAudioSession() {
        do {
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default)
            try AVAudioSession.sharedInstance().setActive(true)
            startRecording()
        } catch {
            print("Failed to set audio session category. \(error)")
        }
    }

    func startRecording() {
        let audioFilename = getDocumentsDirectory().appendingPathComponent("recording.m4a")

        let settings = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 12000,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]

        do {
            audioRecorder = try AVAudioRecorder(url: audioFilename, settings: settings)
            audioRecorder?.record()
        } catch {
            print("Could not start recording: \(error)")
        }
    }

    func stopRecording() {
        audioRecorder?.stop()
        try? AVAudioSession.sharedInstance().setActive(false)
        print("Recording stopped.")
    }

    func getDocumentsDirectory() -> URL {
        let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
        return paths[0]
    }
}
```

このコードでは以下の変更を加えています：

- `stopRecording()` メソッドを追加しました。このメソッドは、`audioRecorder` オブジェクトの `stop` メソッドを呼び出してレコーディングを停止します。その後、オーディオセッションを非アクティブに設定して、リソースを解放します。

- `print("Recording stopped.")` を追加して、レコーディングが停止したことをコンソールに表示します。

このクラスを利用することで、iOSデバイス上で簡単に音声の録音と停止が行えるようになります。使用する際は、適切なタイミングで `startRecording()` と `stopRecording()` を呼び出してください。

---

## 👤 ユーザー
*2024/5/7 10:56:45*

レコードした音源を一覧表示するSwiftUIのコードを書いてほしい

---

## 🤖 アシスタント
*2024/5/7 10:57:33*

音声ファイルの一覧を表示するためのSwiftUIビューを作成するコード例を以下に示します。この例では、ドキュメントディレクトリ内のファイルを取得し、リストで表示します。ユーザーがリストの項目をタップすると、その音声ファイルを再生するシンプルな機能も含めています。

まずは、音声ファイルの再生を担当する単純なオーディオプレーヤークラスを作成します。

```swift
import SwiftUI
import AVFoundation

class AudioPlayer: ObservableObject {
    var player: AVAudioPlayer?

    func playAudio(from url: URL) {
        do {
            player = try AVAudioPlayer(contentsOf: url)
            player?.play()
        } catch {
            print("Audio playback failed: \(error)")
        }
    }
}
```

次に、音声ファイルの一覧を取得し表示するSwiftUIビューを作成します。

```swift
struct AudioListView: View {
    @State private var audioFiles: [URL] = []
    @ObservedObject var audioPlayer = AudioPlayer()

    var body: some View {
        NavigationView {
            List(audioFiles, id: \.self) { fileUrl in
                Button(action: {
                    self.audioPlayer.playAudio(from: fileUrl)
                }) {
                    Text(fileUrl.lastPathComponent)
                        .padding()
                }
            }
            .navigationBarTitle("Recordings")
            .onAppear {
                loadAudioFiles()
            }
        }
    }

    func loadAudioFiles() {
        let fileManager = FileManager.default
        let documentsPath = fileManager.urls(for: .documentDirectory, in: .userDomainMask).first!
        do {
            let audioFilePaths = try fileManager.contentsOfDirectory(at: documentsPath, includingPropertiesForKeys: nil)
            audioFiles = audioFilePaths.filter { $0.pathExtension == "m4a" }
        } catch {
            print("Failed to read audio files: \(error)")
        }
    }
}
```

このコードでは以下の機能が含まれています：

- `AudioListView` は音声ファイルを一覧表示するビューです。リスト内の各項目はボタンとして表示され、タップすると対応する音声ファイルが再生されます。
- `loadAudioFiles` メソッドは、ドキュメントディレクトリから `.m4a` 拡張子のファイルのみをフィルタリングしてリストにロードします。
- `AudioPlayer` クラスは、指定されたURLから音声を再生します。

このコードを使用するには、プロジェクトの適切な場所にビューを配置し、必要に応じてプロジェクトのナビゲーションフローに組み込んでください。

---

## 👤 ユーザー
*2024/5/7 11:40:41*

iOS標準のレコーディングアプリのような画面を実装してほしい。

SwiftUI でなるべくモダンな実装をしてほしい。

機能としては以下である


- レコーディングの開始
- レコーディングの停止
- レコーディング情報の一覧の表示
- レコーディングしたデータの再生の開始
- レコーディングしたデータの再生の停止
- レコーディング情報の削除

ただし、上2つと下4つは画面を分けてほしい

---

## 🤖 アシスタント
*2024/5/7 11:41:41*

iOS標準のレコーディングアプリのような機能を持つアプリをSwiftUIで実装するために、以下の2つの主要なビューを作成します：

1. **レコーディングビュー**：レコーディングの開始と停止を行います。
2. **オーディオリストビュー**：レコーディングしたデータの一覧表示、再生、削除を行います。

まず、共通で使用する`AudioRecorder`クラスと`AudioPlayer`クラスを定義します。

### AudioRecorder.swift
```swift
import Foundation
import AVFoundation

class AudioRecorder: ObservableObject {
    var audioRecorder: AVAudioRecorder?
    @Published var recordings = [Recording]()

    func startRecording() {
        let audioFilename = getDocumentsDirectory().appendingPathComponent("\(Date().toString(dateFormat: "dd-MM-YY_'at'_HH:mm:ss")).m4a")

        let settings = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 12000,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]

        do {
            audioRecorder = try AVAudioRecorder(url: audioFilename, settings: settings)
            audioRecorder?.record()
        } catch {
            print("Could not start recording: \(error)")
        }
    }

    func stopRecording() {
        audioRecorder?.stop()
        loadRecordings()
    }

    func loadRecordings() {
        recordings = FileManager.default.fetchRecordings()
    }

    private func getDocumentsDirectory() -> URL {
        FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    }
}
```

### AudioPlayer.swift
```swift
import Foundation
import AVFoundation

class AudioPlayer: ObservableObject {
    var player: AVAudioPlayer?

    func playAudio(_ recording: Recording) {
        do {
            player = try AVAudioPlayer(contentsOf: recording.fileURL)
            player?.play()
        } catch {
            print("Playback failed: \(error)")
        }
    }

    func stopAudio() {
        player?.stop()
    }
}
```

### Recording.swift
```swift
import Foundation

struct Recording {
    let fileURL: URL
    let createdAt: Date

    var fileName: String {
        fileURL.lastPathComponent
    }
}
```

### RecorderView.swift
```swift
import SwiftUI

struct RecorderView: View {
    @ObservedObject var audioRecorder: AudioRecorder

    var body: some View {
        VStack {
            Button(action: {
                if audioRecorder.audioRecorder == nil {
                    audioRecorder.startRecording()
                } else {
                    audioRecorder.stopRecording()
                }
            }) {
                Image(systemName: audioRecorder.audioRecorder == nil ? "record.circle" : "stop.circle")
                    .resizable()
                    .aspectRatio(contentMode: .fill)
                    .frame(width: 70, height: 70)
                    .clipped()
                    .foregroundColor(.red)
            }
            .padding()
        }
        .navigationBarTitle("Recorder")
    }
}
```

### AudioListView.swift
```swift
import SwiftUI

struct AudioListView: View {
    @ObservedObject var audioRecorder: AudioRecorder
    @ObservedObject var audioPlayer: AudioPlayer

    var body: some View {
        List {
            ForEach(audioRecorder.recordings, id: \.fileName) { recording in
                HStack {
                    Text(recording.fileName)
                    Spacer()
                    Button(action: {
                        audioPlayer.playAudio(recording)
                    }) {
                        Image(systemName: "play.circle")
                    }
                    Button(action: {
                        audioRecorder.deleteRecording(recording)
                    }) {
                        Image(systemName: "trash")
                    }
                }
            }
        }
        .onAppear(perform: audioRecorder.loadRecordings)
        .navigationBarTitle("Recordings")
    }
}
```

このコードには、SwiftUIビューでのレコーディング操作、ファイルの再生、および削除機能が含まれています。FileManager拡張でファイル操作を補助するメソッドを追加し、適切にプロジェクト内で処理してください。各ビューはナビゲーションリンクまたはタブで切り替え可能です。

---

## 👤 ユーザー
*2024/5/7 11:51:59*

以下の処理っていらないの？

try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default)
            try AVAudioSession.sharedInstance().setActive(true)

---

## 🤖 アシスタント
*2024/5/7 11:52:47*

はい、その通りです。iOSでオーディオ録音や再生を行う場合、`AVAudioSession` の設定は非常に重要です。特に、マイクからの録音を行う場合には `AVAudioSession` を適切に設定して、アプリがオーディオを使用することをシステムに伝え、他のオーディオとの優先順位を管理する必要があります。

`AudioRecorder`クラスの中に`AVAudioSession`の設定を組み込む例を以下に示します。録音開始前にセッションカテゴリを設定し、録音が終了した後にセッションを非アクティブにする処理を追加しています。

### AudioRecorder.swift（更新版）
```swift
import Foundation
import AVFoundation

class AudioRecorder: ObservableObject {
    var audioRecorder: AVAudioRecorder?
    @Published var recordings = [Recording]()

    func startRecording() {
        let audioFilename = getDocumentsDirectory().appendingPathComponent("\(Date().toString(dateFormat: "dd-MM-YY_'at'_HH:mm:ss")).m4a")
        let settings = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 12000,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]

        do {
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default)
            try AVAudioSession.sharedInstance().setActive(true)
            audioRecorder = try AVAudioRecorder(url: audioFilename, settings: settings)
            audioRecorder?.record()
        } catch {
            print("Failed to start recording: \(error)")
        }
    }

    func stopRecording() {
        audioRecorder?.stop()
        try? AVAudioSession.sharedInstance().setActive(false)
        loadRecordings()
    }

    func loadRecordings() {
        recordings = FileManager.default.fetchRecordings()
    }

    private func getDocumentsDirectory() -> URL {
        FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    }
}
```

このコードでは、録音を開始する前にオーディオセッションのカテゴリを `playAndRecord` に設定して、アプリが再生と録音の両方を行うことをシステムに伝えています。また、録音が終了した後にオーディオセッションを非アクティブにすることで、他のアプリケーションがオーディオを使用する際の競合を防ぎます。

このように設定することで、アプリのオーディオ機能がより安定し、他のオーディオソースとの干渉を避けることができます。

---

## 👤 ユーザー
*2024/5/7 15:27:18*

fetchRecordings ってなに？あと、m4a だけではなく以下のようなenumで定義した拡張子に対応したい。

public enum AudioFileExtension: String {
    case m4a
    case mp3
}

---

## 🤖 アシスタント
*2024/5/7 15:28:23*

`fetchRecordings` は、ここでは仮に定義した関数で、デバイスのストレージから録音ファイルのリストを取得する目的で使われます。実際には、この関数の実装が必要です。

また、指定された `AudioFileExtension` enumを使って、異なるファイル形式（`.m4a` と `.mp3`）の録音ファイルを扱うことも考慮します。以下に、FileManagerを拡張して録音ファイルをフェッチする方法と、`AudioRecorder` クラスのアップデートを示します。

### FileManagerの拡張
```swift
import Foundation

extension FileManager {
    func fetchRecordings() -> [Recording] {
        let documentsPath = urls(for: .documentDirectory, in: .userDomainMask).first!
        do {
            let audioFiles = try contentsOfDirectory(at: documentsPath, includingPropertiesForKeys: nil)
            return audioFiles.filter { $0.pathExtension == AudioFileExtension.m4a.rawValue || $0.pathExtension == AudioFileExtension.mp3.rawValue }
                           .map { Recording(fileURL: $0, createdAt: getFileCreationDate(url: $0) ?? Date()) }
        } catch {
            print("Failed to read audio files: \(error)")
            return []
        }
    }

    private func getFileCreationDate(url: URL) -> Date? {
        try? url.resourceValues(forKeys: [.creationDateKey]).creationDate
    }
}
```

### AudioRecorder.swift（更新版）
```swift
import Foundation
import AVFoundation

class AudioRecorder: ObservableObject {
    var audioRecorder: AVAudioRecorder?
    @Published var recordings = [Recording]()

    func startRecording(fileExtension: AudioFileExtension = .m4a) {
        let audioFilename = getDocumentsDirectory().appendingPathComponent("\(Date().toString(dateFormat: "dd-MM-YY_'at'_HH:mm:ss")).\(fileExtension.rawValue)")
        let settings = [
            AVFormatIDKey: fileExtension == .m4a ? Int(kAudioFormatMPEG4AAC) : Int(kAudioFormatMPEGLayer3),
            AVSampleRateKey: 12000,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]

        do {
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default)
            try AVAudioSession.sharedInstance().setActive(true)
            audioRecorder = try AVAudioRecorder(url: audioFilename, settings: settings)
            audioRecorder?.record()
        } catch {
            print("Failed to start recording: \(error)")
        }
    }

    func stopRecording() {
        audioRecorder?.stop()
        try? AVAudioSession.sharedInstance().setActive(false)
        loadRecordings()
    }

    func loadRecordings() {
        recordings = FileManager.default.fetchRecordings()
    }

    private func getDocumentsDirectory() -> URL {
        FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    }
}
```

このコードでは以下の機能が含まれています：
- `fetchRecordings` 関数は `FileManager` の拡張として定義されており、指定されたディレクトリからサポートされているファイル拡張子の録音ファイルを取得します。
- `AudioRecorder` には、録音を開始する際にファイル形式を指定するための `fileExtension` パラメータが追加されています。また、適切なフォーマットIDを設定するための条件分岐が含まれています。

このコードを利用することで、アプリケーションは `.m4a` と `.mp3` 形式のファイルを録音し、管理することが可能になります。

---

## 👤 ユーザー
*2024/5/7 15:28:53*

getFileCreationDate はなんのために行われているの？

あとできるだけ多くのメタデータも画面に表示したいと思う

---

## 🤖 アシスタント
*2024/5/7 15:29:58*

`getFileCreationDate`関数は、ファイルのメタデータからそのファイルが作成された日付を取得するために使用されます。これは、ファイル一覧にファイルの作成日を表示したい場合に役立ちます。ファイルの一覧表示時に作成日だけでなく、他のメタデータも表示することが多くのアプリケーションで求められることがあります。例えば、ファイルの長さ（再生時間）、ファイルサイズ、ビットレートなどが考えられます。

### ファイルのメタデータを取得する方法
以下は、録音ファイルのより詳細なメタデータを取得し、それらをアプリケーションのUIに表示する方法を示すコード例です。

1. **メタデータの取得を担う関数の定義**
    - 作成日時だけでなく、ファイルサイズや再生時間も取得します。

2. **`Recording`構造体を更新して、新たに取得するメタデータを保持できるようにします。**

### FileManagerの拡張（更新版）
```swift
import AVFoundation

extension FileManager {
    func fetchRecordings() -> [Recording] {
        let documentsPath = urls(for: .documentDirectory, in: .userDomainMask).first!
        do {
            let audioFiles = try contentsOfDirectory(at: documentsPath, includingPropertiesForKeys: nil)
            return audioFiles.map { fileURL -> Recording? in
                let attributes = try? attributesOfItem(atPath: fileURL.path)
                let fileSize = attributes?[.size] as? Int64
                let creationDate = attributes?[.creationDate] as? Date
                let duration = getAudioDuration(fileURL: fileURL)
                return Recording(fileURL: fileURL, createdAt: creationDate ?? Date(), fileSize: fileSize, duration: duration)
            }
            .compactMap { $0 }
        } catch {
            print("Failed to read audio files: \(error)")
            return []
        }
    }

    private func getAudioDuration(fileURL: URL) -> TimeInterval {
        let asset = AVURLAsset(url: fileURL)
        return CMTimeGetSeconds(asset.duration)
    }
}
```

### Recording.swift（更新版）
```swift
import Foundation

struct Recording {
    let fileURL: URL
    let createdAt: Date
    let fileSize: Int64?
    let duration: TimeInterval

    var fileName: String {
        fileURL.lastPathComponent
    }

    var formattedSize: String {
        guard let fileSize = fileSize else { return "Unknown size" }
        if fileSize < 1024 {
            return "\(fileSize) bytes"
        } else if fileSize < 1024 * 1024 {
            return "\(fileSize / 1024) KB"
        } else {
            return "\(fileSize / (1024 * 1024)) MB"
        }
    }

    var formattedDuration: String {
        let hours = Int(duration / 3600)
        let minutes = Int((duration / 60).truncatingRemainder(dividingBy: 60))
        let seconds = Int(duration.truncatingRemainder(dividingBy: 60))
        if hours > 0 {
            return String(format: "%02i:%02i:%02i", hours, minutes, seconds)
        } else {
            return String(format: "%02i:%02i", minutes, seconds)
        }
    }
}
```

このコードにより、各録音ファイルの作成日、ファイルサイズ、再生時間を取得し、これらの情報をユーザーインターフェースで表示することができます。FileManagerの拡張を通じて、ファイルに関する詳細情報を一覧で見やすく表示することが可能になります。

---

## 👤 ユーザー
*2024/5/7 15:38:12*

Recording を AudioMetadata にしてほしい。特定のフォルダから特定の拡張子のファイルを抽出するようなメソッドはないのか？
fileSize: Int64? を Int にしてほしい。不明な場合は 0 秒でよい。formattedSize や  formattedDuration は公式の関数などで提供されていないのか？

割り算はquotientAndRemainderを使ってほしい

---

## 🤖 アシスタント
*2024/5/7 15:39:14*

構造体名を`Recording`から`AudioMetadata`に変更し、ファイルサイズを`Int64?`から`Int`に変更し、`FileManager`の拡張で特定のフォルダから特定の拡張子のファイルを抽出するメソッドを追加しましょう。また、`formattedSize`と`formattedDuration`をより正確に計算するために`quotientAndRemainder`を使用します。

### FileManagerの拡張（更新版）

```swift
import AVFoundation

extension FileManager {
    func fetchAudioMetadata(folder: URL, extensions: [AudioFileExtension]) -> [AudioMetadata] {
        do {
            let audioFiles = try contentsOfDirectory(at: folder, includingPropertiesForKeys: nil)
            return audioFiles.filter { fileURL in
                extensions.contains { $0.rawValue == fileURL.pathExtension }
            }
            .compactMap { fileURL -> AudioMetadata? in
                let attributes = try? attributesOfItem(atPath: fileURL.path)
                let fileSize = (attributes?[.size] as? Int) ?? 0
                let creationDate = attributes?[.creationDate] as? Date ?? Date()
                let duration = getAudioDuration(fileURL: fileURL)
                return AudioMetadata(fileURL: fileURL, createdAt: creationDate, fileSize: fileSize, duration: duration)
            }
        } catch {
            print("Failed to read audio files: \(error)")
            return []
        }
    }

    private func getAudioDuration(fileURL: URL) -> TimeInterval {
        let asset = AVURLAsset(url: fileURL)
        return CMTimeGetSeconds(asset.duration)
    }
}
```

### AudioMetadata.swift（更新版）

```swift
import Foundation

struct AudioMetadata {
    let fileURL: URL
    let createdAt: Date
    let fileSize: Int
    let duration: TimeInterval

    var fileName: String {
        fileURL.lastPathComponent
    }

    var formattedSize: String {
        if fileSize < 1024 {
            return "\(fileSize) bytes"
        } else {
            let (kb, _) = fileSize.quotientAndRemainder(dividingBy: 1024)
            if kb < 1024 {
                return "\(kb) KB"
            } else {
                let (mb, _) = kb.quotientAndRemainder(dividingBy: 1024)
                return "\(mb) MB"
            }
        }
    }

    var formattedDuration: String {
        let (minutes, secondsRemainder) = Int(duration).quotientAndRemainder(dividingBy: 60)
        let (hours, minutesRemainder) = minutes.quotientAndRemainder(dividingBy: 60)
        let seconds = secondsRemainder
        if hours > 0 {
            return String(format: "%02i:%02i:%02i", hours, minutesRemainder, seconds)
        } else {
            return String(format: "%02i:%02i", minutesRemainder, seconds)
        }
    }
}
```

この更新では、次の変更を加えました：

- `Recording`を`AudioMetadata`に名前変更しました。
- `FileManager`の拡張メソッド`fetchAudioMetadata`を追加し、指定されたフォルダ内の特定の拡張子を持つファイルだけをフィルタリングして取得します。
- ファイルサイズのデフォルトを0に設定しました。
- `formattedSize`と`formattedDuration`の計算に`quotientAndRemainder`を使用しています。

これで、特定のフォルダから特定のファイル拡張子を持つファイルを取得し、そのファイルに関する詳細なメタデータを取得して表示することが可能になります。

---

## 👤 ユーザー
*2024/5/7 15:44:01*

var formattedSize: String {
        if fileSize &lt; 1024 {
            return "\(fileSize) bytes"
        } else {
            let (kb, _) = fileSize.quotientAndRemainder(dividingBy: 1024)
            if kb &lt; 1024 {
                return "\(kb) KB"
            } else {
                let (mb, _) = kb.quotientAndRemainder(dividingBy: 1024)
                return "\(mb) MB"
            }
        }
    } はquotientAndRemainderを使わなくていい。また、Intのコンピューテッドプロパティーとして一般的に拡張して、ほしい。

---

## 🤖 アシスタント
*2024/5/7 15:44:52*

ファイルサイズの表示をより一般的に使えるように`Int`型の拡張として`formattedSize`プロパティを定義します。ここで、`quotientAndRemainder`を使用する必要はないため、より単純な方法で実装します。以下のコードは`Int`型に対する拡張としてファイルサイズのフォーマット変換を提供します。

### Int Extension for Formatted File Size

```swift
extension Int {
    var formattedSize: String {
        if self < 1024 {
            return "\(self) bytes"
        } else if self < 1_048_576 { // 1024 * 1024
            return "\((self / 1024)) KB"
        } else if self < 1_073_741_824 { // 1024 * 1024 * 1024
            return "\((self / 1_048_576)) MB"
        } else {
            return "\((self / 1_073_741_824)) GB"
        }
    }
}
```

この拡張を使用すると、`Int`型の任意の整数に対して`.formattedSize`を呼び出して、読みやすいファイルサイズ形式を取得できます。例えば、`fileSize.formattedSize`のように使用でき、自動的に適切な単位（バイト、キロバイト、メガバイト、ギガバイト）でフォーマットされた文字列を返します。

### AudioMetadata.swiftの更新

`AudioMetadata`構造体では、`fileSize`の型を`Int`として定義し、`formattedSize`プロパティを使う必要はありません。代わりに、ファイルサイズを表示する際に、この拡張を直接使用します。

```swift
struct AudioMetadata {
    let fileURL: URL
    let createdAt: Date
    let fileSize: Int
    let duration: TimeInterval

    var fileName: String {
        fileURL.lastPathComponent
    }

    var formattedDuration: String {
        let (minutes, secondsRemainder) = Int(duration).quotientAndRemainder(dividingBy: 60)
        let (hours, minutesRemainder) = minutes.quotientAndRemainder(dividingBy: 60)
        let seconds = secondsRemainder
        if hours > 0 {
            return String(format: "%02i:%02i:%02i", hours, minutesRemainder, seconds)
        } else {
            return String(format: "%02i:%02i", minutesRemainder, seconds)
        }
    }
}
```

この変更により、ファイルサイズを表示するためのコードが簡素化され、他の整数値にも同様のフォーマットを適用することができるようになります。

---

## 👤 ユーザー
*2024/5/7 15:46:56*

format: "%02i:%02i:%02i" や format: "%02i:%02i" はなんですか？

---

## 🤖 アシスタント
*2024/5/7 15:47:36*

`format: "%02i:%02i:%02i"` と `format: "%02i:%02i"` は、Swift での文字列フォーマット指定です。これらの書式指定子を使用すると、数値を特定のフォーマットで文字列に変換できます。この形式は、特に時間や数値を視覚的に整理して表示する場面で有用です。

### 書式指定の詳細:

1. **`%02i`**:
   - `%i` は整数を意味します。
   - `02` は少なくとも2桁の数を表示し、不足している場合はゼロで埋めることを指示します。例えば、`1` は `01` として表示されます。これは特に時刻表示において一般的なフォーマットです。

2. **コロン(`:`)**:
   - 時間の部分（時、分、秒）を区切るために使用されます。

### 使用例:

- **`"%02i:%02i:%02i"`**:
  - 3つの整数値（例えば時、分、秒）を取り、それぞれ2桁で表示します。時間が `9` 時 `2` 分 `5` 秒の場合、`"09:02:05"` と表示されます。

- **`"%02i:%02i"`**:
  - 2つの整数値（例えば分と秒）を取り、同様にそれぞれ2桁で表示します。分が `2` で秒が `9` の場合、`"02:09"` と表示されます。

このようなフォーマットは、時刻やタイマー、スポーツのタイムトラッキングなど、時間を扱う多くのアプリケーションで使われます。整数の表示を一貫性があり、読みやすくするために重要なツールです。

---

## 👤 ユーザー
*2024/5/7 15:47:47*

これってSwiftの標準機能で搭載されていないの？

---

## 🤖 アシスタント
*2024/5/7 15:48:42*

Swift の標準ライブラリでは、特定のフォーマットで時間を整形して表示する直接的な機能は提供されていません。しかし、Swift と iOS SDK には `DateFormatter` や `DateComponentsFormatter` などのクラスが含まれており、これらを使用して時間や日付を任意のフォーマットで表示することができます。特に時間のフォーマットに関しては `DateComponentsFormatter` が適しています。

### DateComponentsFormatter の使用例

時間の長さをフォーマットするために `DateComponentsFormatter` を使う例を以下に示します。これを使えば、時間、分、秒を含む期間を適切にフォーマットすることができます。

```swift
import Foundation

func formattedDuration(from totalSeconds: TimeInterval) -> String {
    let formatter = DateComponentsFormatter()
    formatter.allowedUnits = [.hour, .minute, .second]
    formatter.unitsStyle = .positional
    formatter.zeroFormattingBehavior = .pad

    return formatter.string(from: totalSeconds) ?? "00:00"
}
```

この関数は `TimeInterval` （秒単位の時間）を受け取り、`DateComponentsFormatter` を使用して、例えば `3661` 秒（1時間1分1秒）を `"01:01:01"` のようにフォーマットします。設定により、時間が存在しない場合でも `00` でパディングされます。

### DateFormatter の使用例

日付や時間を特定のスタイルでフォーマットしたい場合には `DateFormatter` を使用します。例えば、特定の日付を「年月日」形式で表示することができます。

```swift
import Foundation

func formattedDate(from date: Date) -> String {
    let formatter = DateFormatter()
    formatter.dateStyle = .long
    formatter.timeStyle = .none
    return formatter.string(from: date)
}
```

この関数は `Date` オブジェクトを受け取り、それを長いスタイルの日付フォーマット（例: "June 27, 2024"）で文字列に変換します。

### まとめ
Swift には、文字列フォーマット機能として `%02i` のようなC言語スタイルの書式指定が利用可能ですが、より高度で直感的な日付や時間のフォーマットには `DateComponentsFormatter` や `DateFormatter` のような専用のクラスを利用するのが一般的です。これにより、多くのロケールやカレンダーに依存するフォーマットのニーズに柔軟に対応することができます。

---

## 👤 ユーザー
*2024/5/7 15:51:28*

DateComponentsFormatterを以下のように使って、Int -&gt; String の変換を一覧化したい。

private extension DateFormatter {
    /// String-&gt;DateとDate-&gt;String変換のためのDateFormatter
    ///
    /// DateFormatterの生成が遅いため、1つのインスタンスを使い回す
    static let shared: DateFormatter = {
        let formatter = DateFormatter()
        formatter.calendar = Calendar(identifier: .gregorian)
        formatter.locale = .current
        return formatter
    }()
}

public extension String {
    /// String -&gt; Date 変換
    func toDate(format: StringToDateFormat) -&gt; Date {
        DateFormatter.shared.dateFormat = format.rawValue
        guard let date = DateFormatter.shared.date(from: self) else {
            assertionFailure("unexpected")
            return Date()
        }
        return date
    }
}

public extension Date {
    /// Date -&gt; String 変換
    func toString(format: DateToStringFormat) -&gt; String {
        DateFormatter.shared.dateFormat = format.rawValue
        return DateFormatter.shared.string(from: self)
    }
}

/// String -&gt; Date 変換用のフォーマット
public enum StringToDateFormat: String {
    case dateFormat = "yyyy-MM-dd"
    case dateTimeNoFractionFormat = "yyyy-MM-dd'T'HH:mm:ss"
    case dateTimeFormat = "yyyy-MM-dd'T'HH:mm:ss.SSSZZZZZ"
}

/// Date -&gt; String 変換用のフォーマット
public enum DateToStringFormat: String {
    case display = "yyyy/MM.dd(EEE)"
    case dateTimeWithWeekDay = "yyyy/MM/dd(EEEEE) HH:mm"
    case dateTimeWithWeekDayNoZero = "yyyy/M/d(EEEEE) H:mm"
    case dateWithWeekDayNoZero = "yyyy/M/d(EEEEE)"
    case dateWithWeekDay = "yyyy/MM/dd(EEEEE)"
    case time = "HH:mm"
    case timeHourNoZero = "H:mm"
    case day = "d"
    case weekDay = "eee"
    case monthDay = "MM/dd"
    case dateWithTime = "yyyy/MM/dd HH:mm"
    case dateWithTimeNoZero = "yyyy/M/d H:mm"
    case monthDayWithTime = "M/d HH:mm"
    case yearNoZeroMonthDay = "yyyy/M/d"
    case yearMonth = "yyyy/MM"
    case yearMonthDay = "yyyy/MM/dd"
    case dateTimeFormat = "yyyy-MM-dd'T'HH:mm:ss.SSSZZZZZ"
    case dateFormat = "yyyy-MM-dd"
    case defaultPictureName = "MM月-dd-yyyy-HH:mm:ss-'JST'-+0900"
    case dateWithTimeInJa = "yyyy年MM月dd日 H:mm"
    case dateTimeFormatForPath = "yyyy-MM-dd_HH-mm-ss-SSS"
    case allIntFormat = "yyyyMMddHHmmss"
    case allIntMsFormat = "yyyyMMddHHmmsss"
    case hhmmsssss = "HH:mm:ss.SSS"
}

---

## 🤖 アシスタント
*2024/5/7 15:52:21*

上記のコードでは、日付と文字列の変換を効率よく行うために`DateFormatter`のインスタンスを共有するパターンを使っています。これにより、多数の日付変換処理を行う場合でもパフォーマンスが向上します。同様に、`DateComponentsFormatter` を使用して時間の整形を行うための拡張も可能です。

以下に`Int`から時間表現の文字列に変換するための拡張を示します。これを使って、例えば秒単位の整数値から読みやすい時間表現へと変換できます。

### DateComponentsFormatterの拡張
`DateComponentsFormatter` を用いた `Int` 型の拡張を以下のように定義します。これにより、整数型の時間（秒数）を「HH:mm:ss」や「mm:ss」などの形式で表現することができるようになります。

```swift
import Foundation

extension Int {
    /// Converts an integer value (seconds) to a formatted string representing time duration.
    var formattedTime: String {
        let formatter = DateComponentsFormatter()
        formatter.allowedUnits = [.hour, .minute, .second]
        formatter.unitsStyle = .positional
        formatter.zeroFormattingBehavior = .pad

        // 時間が1時間未満の場合、"00:"を省略する
        if self < 3600 {
            formatter.allowedUnits = [.minute, .second]
        }

        return formatter.string(from: TimeInterval(self)) ?? "00:00"
    }
}
```

この拡張は、秒数を取得して `DateComponentsFormatter` により整形された時間表現の文字列に変換します。時間が1時間未満の場合には、時間部分を表示しないようにしています。

### 使用例
この拡張を使うことで、例えばアプリ内でタイマー機能を実装する際や、ある期間の秒数を読みやすい形で表示する際に役立ちます。

```swift
let durationInSeconds = 3661  // 1時間1分1秒
print(durationInSeconds.formattedTime)  // "01:01:01"

let shortDurationInSeconds = 61  // 1分1秒
print(shortDurationInSeconds.formattedTime)  // "01:01"
```

この拡張を使うことで、整数値の秒数を直感的に理解しやすい形で表現することができ、アプリのユーザーインターフェースを向上させることが可能です。また、拡張の中で`DateComponentsFormatter`の設定を調整することで、さまざまな表示要件に柔軟に対応することもできます。

---

## 👤 ユーザー
*2024/5/7 15:53:35*

DateComponentsFormatter と DateFormatter の違いを教えてほしい

---

## 🤖 アシスタント
*2024/5/7 15:54:40*

`DateComponentsFormatter` と `DateFormatter` はどちらも Swift および Objective-C の一部として Apple の Foundation フレームワークに含まれていますが、それぞれ異なる目的と使用ケースがあります。

### DateFormatter
`DateFormatter` は日付と文字列の間で変換を行うクラスです。具体的には、日付オブジェクト (`Date`) を人間が読める文字列形式に変換したり、逆に文字列から日付オブジェクトを生成したりする際に使用されます。このクラスはロケール、タイムゾーン、カレンダースタイルに基づいたフォーマットをサポートしており、日付と時刻を表示するための多様なカスタマイズが可能です。

- **例**: "2024-01-01" から `Date` オブジェクトを生成する、または `Date` オブジェクトを "January 1, 2024" のような形式で表示する。

```swift
let formatter = DateFormatter()
formatter.dateFormat = "yyyy-MM-dd"
let date = formatter.date(from: "2024-01-01")  // String to Date
formatter.dateStyle = .long
let dateString = formatter.string(from: date!)  // Date to String, outputs "January 1, 2024"
```

### DateComponentsFormatter
`DateComponentsFormatter` は時間の間隔を表すために使用されます。このクラスは特定の時間（例えば秒数）を「2 hours, 10 minutes」や「2時間10分」といった形式の文字列に変換するために設計されています。`DateComponentsFormatter` は時間間隔を表現するために最適化されており、特にユーザーにとって読みやすい形式で時間を表示する場合に便利です。

- **例**: 3910秒を "1 hour, 5 minutes, 10 seconds" という形式で表示する。

```swift
let formatter = DateComponentsFormatter()
formatter.unitsStyle = .full
formatter.allowedUnits = [.hour, .minute, .second]
let timeString = formatter.string(from: 3910)  // outputs "1 hour, 5 minutes, 10 seconds"
```

### 主な違い
- **用途**:
  - `DateFormatter`: 日付と時刻を人間が読める形で表示したり、日付の文字列を解析したりするために使用します。
  - `DateComponentsFormatter`: 時間間隔（持続期間）をフォーマットするために使用し、例えばスポーツアプリでのラップタイムやクッキングタイマーなどに適しています。

- **機能**:
  - `DateFormatter`: ロケールやタイムゾーンに依存する日付のフォーマットをサポートします。
  - `DateComponentsFormatter`: 時間間隔の単位（秒、分、時間）を選択し、それらを組み合わせて表示する方法を提供します。

両者は目的が異なり、アプリケーションの特定のニーズに応じて選択することが重要です。日付や時刻を扱う際には `DateFormatter` を、時間間隔や持続期間を扱う際には `DateComponentsFormatter` を使用します。

---

## 👤 ユーザー
*2024/5/7 17:32:45*

DateComponentsFormatter はシングルトン的につかったほうがいいのかな？

---

## 🤖 アシスタント
*2024/5/7 17:34:01*

`DateComponentsFormatter` や `DateFormatter` のような日付関連のフォーマッターは、インスタンスの生成が比較的コストがかかる操作です。これは、これらのフォーマッターが内部的に多くの設定を管理しており、ロケールやタイムゾーンなどの環境設定に基づいて適切に動作するように設計されているためです。

そのため、これらのフォーマッターを頻繁に作成し、短期間で破棄するような使い方は効率が良くありません。代わりに、以下のようなシナリオでシングルトンパターンや類似の手法を採用することが一般的に推奨されます：

### シングルトン的使用のメリット
- **パフォーマンスの最適化**: フォーマッターのインスタンスをアプリケーション全体で再利用することで、インスタンス生成のコストを削減し、全体的なパフォーマンスを向上させます。
- **メモリ使用の削減**: 同じ種類のフォーマッターを複数生成する代わりに、単一のインスタンスを共有することでメモリ消費を抑えることができます。

### 実装例
以下は `DateComponentsFormatter` をシングルトン的に利用する例です。この方法は、特にフォーマッターがアプリ全体で一貫した設定で使用される場合に適しています。

```swift
import Foundation

class FormatterProvider {
    static let shared = FormatterProvider()

    let durationFormatter: DateComponentsFormatter

    private init() {
        durationFormatter = DateComponentsFormatter()
        durationFormatter.unitsStyle = .abbreviated
        durationFormatter.allowedUnits = [.hour, .minute, .second]
        durationFormatter.zeroFormattingBehavior = .pad
    }
}

// 使用例
let formattedDuration = FormatterProvider.shared.durationFormatter.string(from: TimeInterval(3661)) ?? "00:00"
```

### 使用時の注意点
シングルトン的なアプローチを取る際には、以下の点に注意してください：

- **スレッドセーフ**: マルチスレッド環境でフォーマッターを使用する場合、インスタンスへのアクセスがスレッドセーフであることを保証する必要があります。`DateComponentsFormatter` のドキュメントには特にスレッドセーフであるとの記述がないため、同時に複数のスレッドからアクセスされる場合はロックなどの同期処理を考慮する必要があります。
- **カスタマイズの柔軟性**: シングルトンインスタンスを使用する場合、その設定変更がアプリ全体に影響を及ぼすことがあります。使用するコンテキストによって異なる設定が必要な場合は、シングルトンではなく、必要に応じて個別のインスタンスを生成する方が適切な場合があります。

シングルトン的な使用が適切かどうかは、そのアプリケーションの具体的な要件と使用シナリオに依存します。多くの場合、これらのフォーマッターを頻繁に使用する場合には、パフォーマンスとメモリ使用のバランスを考慮してシングルトン的なアプローチが有効です。

---

## 👤 ユーザー
*2024/5/7 17:43:56*

こういうイメージだった

public extension ISO8601DateFormatter {
    static let sharedWithFractionalSeconds: ISO8601DateFormatter = {
        let formatter = ISO8601DateFormatter()
        formatter.formatOptions = [.withInternetDateTime, .withFractionalSeconds]
        formatter.timeZone = TimeZone.current
        return formatter
    }()
}

---

## 🤖 アシスタント
*2024/5/7 17:44:46*

理解しました。ご提示いただいたコードのスタイルを踏襲して、`DateComponentsFormatter` をシングルトン的に使用するための Swift 拡張を書くことは、パフォーマンス最適化の観点からも良いアプローチです。`ISO8601DateFormatter` の例と同様に、`DateComponentsFormatter` のインスタンスを共有して再利用することで、インスタンス生成のコストを削減し、アプリケーションの効率を向上させることができます。

以下に `DateComponentsFormatter` 用のシングルトン的な拡張を示します：

```swift
import Foundation

public extension DateComponentsFormatter {
    static let shared: DateComponentsFormatter = {
        let formatter = DateComponentsFormatter()
        formatter.unitsStyle = .full
        formatter.allowedUnits = [.hour, .minute, .second]
        formatter.zeroFormattingBehavior = .pad
        return formatter
    }()
}
```

この拡張を利用することで、`DateComponentsFormatter` のインスタンスをアプリケーション全体で使い回すことができます。これにより、繰り返し同じ種類のフォーマットを使用する際の効率が向上します。

### 使用例
シングルトン的な`DateComponentsFormatter`を使って、秒数を人間が読める形式に変換します。

```swift
let durationInSeconds = 3661  // 1時間1分1秒
if let formattedString = DateComponentsFormatter.shared.string(from: TimeInterval(durationInSeconds)) {
    print(formattedString)  // "1 hour, 1 minute, 1 second"（ロケールにより異なる）
}
```

この方法では、フォーマッタの設定を一箇所で管理でき、アプリケーション内のどこからでも同じ設定で時間をフォーマットできるため、一貫性が保たれます。ただし、異なるフォーマット設定を頻繁に切り替える必要がある場合は、それぞれの設定に合わせて別のインスタンスを用意するか、設定を動的に変更できるようにすることが重要です。

---

## 👤 ユーザー
*2024/5/7 18:19:32*

AudioFileUrl から AudioMetadata を取得する関数を作ってあげた方がスマートな気がしてきた。また、拡張子で抽出する処理も別関数で定義してあげたほうがスマートな気がしてきた。

extension FileManager {
    func fetchRecordings(folder: URL, extensions: [FileExtension]) throws -&gt; [AudioMetadata] {
        do {
            return try contentsOfDirectory(at: folder, includingPropertiesForKeys: nil).filter { fileUrl in
                extensions.contains { $0.pathExtension == fileUrl.pathExtension }
            }
            .map { fileUrl -&gt; AudioMetadata in
                let attributes = try attributesOfItem(atPath: fileUrl.path)
                let fileSize: Int = (attributes[.size] as? Int) ?? 0
                let creationDate: Date = attributes[.creationDate] as? Date ?? Date()
                let duration: TimeInterval = CMTimeGetSeconds(AVURLAsset(url: fileUrl).duration)
                return AudioMetadata(
                    fileUrl: fileUrl,
                    createdAt: creationDate,
                    fileSize: fileSize,
                    duration: duration
                )
            }
        } catch {
            print("Failed to read audio files: \(error)")
            throw error
        }
    }
}

---

## 🤖 アシスタント
*2024/5/7 18:20:40*

指摘の通り、`FileManager` の拡張を使って特定のフォルダから特定の拡張子を持つファイルのメタデータを取得する関数を整理し、それを`AudioMetadata`オブジェクトにマッピングするアプローチは非常に合理的です。また、ファイルを拡張子に基づいてフィルタリングするロジックを別の関数に分割することもコードの再利用性と明瞭さを高めるために役立ちます。

以下は、提供されたコードに基づいて、いくつかの改善を施したバージョンです。これには、エラー処理を改善し、ファイルフィルタリングを別のメソッドで行うように分割しました。

### FileExtension Enum
まず、使用するファイル拡張子を定義するための `enum` を作成します。

```swift
public enum FileExtension: String {
    case m4a
    case mp3
}
```

### FileManager Extension
次に、`FileManager` の拡張を行い、拡張子に基づくフィルタリングとメタデータの抽出を行います。

```swift
import Foundation
import AVFoundation

extension FileManager {
    func fetchRecordings(folder: URL, extensions: [FileExtension]) throws -> [AudioMetadata] {
        let audioFiles = try fetchFiles(at: folder, extensions: extensions)
        return try audioFiles.map(metadataFromAudioFile)
    }
    
    private func fetchFiles(at folder: URL, extensions: [FileExtension]) throws -> [URL] {
        return try contentsOfDirectory(at: folder, includingPropertiesForKeys: nil).filter { fileUrl in
            extensions.contains { $0.rawValue == fileUrl.pathExtension }
        }
    }
    
    private func metadataFromAudioFile(fileUrl: URL) throws -> AudioMetadata {
        let attributes = try attributesOfItem(atPath: fileUrl.path)
        let fileSize = (attributes[.size] as? Int) ?? 0
        let creationDate = attributes[.creationDate] as? Date ?? Date()
        let duration = CMTimeGetSeconds(AVURLAsset(url: fileUrl).duration)
        
        return AudioMetadata(
            fileUrl: fileUrl,
            createdAt: creationDate,
            fileSize: fileSize,
            duration: duration
        )
    }
}
```

このコードは、次のように機能します：

1. **fetchFiles**: 特定のフォルダから指定された拡張子を持つファイルのURLを抽出します。このメソッドはファイルの拡張子をチェックし、指定された拡張子のリストに含まれるファイルだけを返します。
2. **metadataFromAudioFile**: 各ファイルのURLから `AudioMetadata` オブジェクトを生成します。ファイルの属性からファイルサイズ、作成日、再生時間を抽出します。

このアプローチは、関数の責務を分離し、再利用可能なコンポーネントを提供することでコードの可読性とメンテナンス性を向上させます。また、エラーが発生した場合には、それを呼び出し元に伝播させ、適切に処理することができます。

---
