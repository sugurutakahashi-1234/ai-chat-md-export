# Swiftで音声URLを操作

日付: 2024-06-24

---

## 👤 ユーザー
*2024/6/24 18:49:26*

Swiftで音声URLの配列をわたしてコントロールセンターの次へと戻るに対応させたい

---

## 🤖 アシスタント
*2024/6/24 18:50:12*

音声URLの配列を渡して、iOSのコントロールセンターの「次へ」と「戻る」に対応させるには、`AVQueuePlayer`を使用するのが一般的です。`AVQueuePlayer`を使うと、複数の音声ファイルを再生リストとして管理し、次のトラックや前のトラックに簡単に移動できます。

以下は、Swiftでの実装例です：

```swift
import AVFoundation
import MediaPlayer

class AudioPlayerManager: NSObject {
    static let shared = AudioPlayerManager()
    private var player: AVQueuePlayer?
    private var playerItems: [AVPlayerItem] = []

    private override init() {
        super.init()
        setupRemoteTransportControls()
    }

    func setupAudioPlayer(with urls: [URL]) {
        playerItems = urls.map { AVPlayerItem(url: $0) }
        player = AVQueuePlayer(items: playerItems)
    }

    func play() {
        player?.play()
    }

    func pause() {
        player?.pause()
    }

    func skipToNext() {
        player?.advanceToNextItem()
    }

    func skipToPrevious() {
        guard let currentItem = player?.currentItem else { return }
        player?.pause()
        player?.insert(currentItem, after: nil)
        player?.play()
    }

    private func setupRemoteTransportControls() {
        let commandCenter = MPRemoteCommandCenter.shared()
        
        commandCenter.playCommand.addTarget { [unowned self] event in
            self.play()
            return .success
        }
        
        commandCenter.pauseCommand.addTarget { [unowned self] event in
            self.pause()
            return .success
        }

        commandCenter.nextTrackCommand.addTarget { [unowned self] event in
            self.skipToNext()
            return .success
        }

        commandCenter.previousTrackCommand.addTarget { [unowned self] event in
            self.skipToPrevious()
            return .success
        }
    }
}
```

### 使用方法

1. 配列で音声URLを渡してプレイヤーをセットアップします：
```swift
let audioURLs: [URL] = [
    URL(string: "https://example.com/audio1.mp3")!,
    URL(string: "https://example.com/audio2.mp3")!
]

AudioPlayerManager.shared.setupAudioPlayer(with: audioURLs)
```

2. 再生、停止、次のトラック、前のトラックに移動するために、`AudioPlayerManager.shared.play()`, `AudioPlayerManager.shared.pause()`, `AudioPlayerManager.shared.skipToNext()`, `AudioPlayerManager.shared.skipToPrevious()`を使用します。

3. コントロールセンターでの操作は、`setupRemoteTransportControls()`メソッドによって対応しています。このメソッドは、リモートコマンドセンターを設定し、再生、停止、次のトラック、前のトラックのコマンドに対応します。

この実装により、iOSのコントロールセンターやロック画面からの操作が可能になります。

---

## 👤 ユーザー
*2024/6/24 18:51:02*

これはストリーミング再生可能なの？

---

## 🤖 アシスタント
*2024/6/24 18:51:44*

`AVQueuePlayer`を使用する場合、URLがストリーミング可能であれば、ストリーミング再生も可能です。ストリーミング再生のURLは通常、HTTP Live Streaming (HLS) フォーマット（拡張子が`.m3u8`）などが使用されます。

以下に、ストリーミング再生に対応した実装例を示します：

```swift
import AVFoundation
import MediaPlayer

class AudioPlayerManager: NSObject {
    static let shared = AudioPlayerManager()
    private var player: AVQueuePlayer?
    private var playerItems: [AVPlayerItem] = []

    private override init() {
        super.init()
        setupRemoteTransportControls()
        setupNowPlayingInfoCenter()
    }

    func setupAudioPlayer(with urls: [URL]) {
        playerItems = urls.map { AVPlayerItem(url: $0) }
        player = AVQueuePlayer(items: playerItems)
    }

    func play() {
        player?.play()
    }

    func pause() {
        player?.pause()
    }

    func skipToNext() {
        player?.advanceToNextItem()
        updateNowPlayingInfo()
    }

    func skipToPrevious() {
        guard let currentItem = player?.currentItem else { return }
        player?.pause()
        player?.insert(currentItem, after: nil)
        player?.play()
        updateNowPlayingInfo()
    }

    private func setupRemoteTransportControls() {
        let commandCenter = MPRemoteCommandCenter.shared()

        commandCenter.playCommand.addTarget { [unowned self] event in
            self.play()
            return .success
        }

        commandCenter.pauseCommand.addTarget { [unowned self] event in
            self.pause()
            return .success
        }

        commandCenter.nextTrackCommand.addTarget { [unowned self] event in
            self.skipToNext()
            return .success
        }

        commandCenter.previousTrackCommand.addTarget { [unowned self] event in
            self.skipToPrevious()
            return .success
        }
    }

    private func setupNowPlayingInfoCenter() {
        // Set up Now Playing Info Center
        let nowPlayingInfoCenter = MPNowPlayingInfoCenter.default()
        nowPlayingInfoCenter.nowPlayingInfo = [
            MPMediaItemPropertyTitle: "Audio Title",
            MPMediaItemPropertyArtist: "Artist Name",
            MPNowPlayingInfoPropertyPlaybackRate: 1.0
        ]
    }

    private func updateNowPlayingInfo() {
        guard let currentItem = player?.currentItem else { return }
        let nowPlayingInfoCenter = MPNowPlayingInfoCenter.default()
        var nowPlayingInfo = nowPlayingInfoCenter.nowPlayingInfo ?? [String: Any]()

        nowPlayingInfo[MPMediaItemPropertyTitle] = "Updated Title"
        nowPlayingInfo[MPMediaItemPropertyArtist] = "Updated Artist"
        nowPlayingInfo[MPNowPlayingInfoPropertyElapsedPlaybackTime] = CMTimeGetSeconds(currentItem.currentTime())
        nowPlayingInfo[MPMediaItemPropertyPlaybackDuration] = CMTimeGetSeconds(currentItem.asset.duration)
        nowPlayingInfo[MPNowPlayingInfoPropertyPlaybackRate] = player?.rate

        nowPlayingInfoCenter.nowPlayingInfo = nowPlayingInfo
    }
}
```

### 使用方法

1. 配列でストリーミングURLを渡してプレイヤーをセットアップします：

```swift
let streamingURLs: [URL] = [
    URL(string: "https://example.com/stream1.m3u8")!,
    URL(string: "https://example.com/stream2.m3u8")!
]

AudioPlayerManager.shared.setupAudioPlayer(with: streamingURLs)
```

2. 再生、停止、次のトラック、前のトラックに移動するために、`AudioPlayerManager.shared.play()`, `AudioPlayerManager.shared.pause()`, `AudioPlayerManager.shared.skipToNext()`, `AudioPlayerManager.shared.skipToPrevious()`を使用します。

3. コントロールセンターやロック画面からの操作も同様に設定されています。

この方法で、ストリーミングURLが提供する音声データを再生し、iOSのコントロールセンターやロック画面からの制御も可能になります。

---

## 👤 ユーザー
*2024/6/24 18:53:26*

ちなみにこれを使ってSwiftUIで音量とかを表示できる？AV audio playerとかでaverage Powerなど取得すれば取れてやつなんだけど

---

## 🤖 アシスタント
*2024/6/24 18:54:43*

SwiftUIで音量を表示するために、`AVAudioRecorder`や`AVAudioPlayer`を使って音量のデータを取得し、そのデータをSwiftUIのビューに反映させることができます。以下に、`AVAudioPlayer`を使用して音量を取得し、SwiftUIで表示する例を示します。

### 1. `AudioPlayerManager`の拡張

まず、音量を取得するための`AudioPlayerManager`を拡張します。

```swift
import AVFoundation
import Combine

class AudioPlayerManager: NSObject, ObservableObject {
    static let shared = AudioPlayerManager()
    private var player: AVQueuePlayer?
    private var playerItems: [AVPlayerItem] = []
    private var timer: Timer?
    
    @Published var currentVolume: Float = 0.0

    private override init() {
        super.init()
        setupRemoteTransportControls()
        setupNowPlayingInfoCenter()
    }

    func setupAudioPlayer(with urls: [URL]) {
        playerItems = urls.map { AVPlayerItem(url: $0) }
        player = AVQueuePlayer(items: playerItems)
        startVolumeMonitoring()
    }

    func play() {
        player?.play()
    }

    func pause() {
        player?.pause()
    }

    func skipToNext() {
        player?.advanceToNextItem()
        updateNowPlayingInfo()
    }

    func skipToPrevious() {
        guard let currentItem = player?.currentItem else { return }
        player?.pause()
        player?.insert(currentItem, after: nil)
        player?.play()
        updateNowPlayingInfo()
    }

    private func setupRemoteTransportControls() {
        let commandCenter = MPRemoteCommandCenter.shared()

        commandCenter.playCommand.addTarget { [unowned self] event in
            self.play()
            return .success
        }

        commandCenter.pauseCommand.addTarget { [unowned self] event in
            self.pause()
            return .success
        }

        commandCenter.nextTrackCommand.addTarget { [unowned self] event in
            self.skipToNext()
            return .success
        }

        commandCenter.previousTrackCommand.addTarget { [unowned self] event in
            self.skipToPrevious()
            return .success
        }
    }

    private func setupNowPlayingInfoCenter() {
        let nowPlayingInfoCenter = MPNowPlayingInfoCenter.default()
        nowPlayingInfoCenter.nowPlayingInfo = [
            MPMediaItemPropertyTitle: "Audio Title",
            MPMediaItemPropertyArtist: "Artist Name",
            MPNowPlayingInfoPropertyPlaybackRate: 1.0
        ]
    }

    private func updateNowPlayingInfo() {
        guard let currentItem = player?.currentItem else { return }
        let nowPlayingInfoCenter = MPNowPlayingInfoCenter.default()
        var nowPlayingInfo = nowPlayingInfoCenter.nowPlayingInfo ?? [String: Any]()

        nowPlayingInfo[MPMediaItemPropertyTitle] = "Updated Title"
        nowPlayingInfo[MPMediaItemPropertyArtist] = "Updated Artist"
        nowPlayingInfo[MPNowPlayingInfoPropertyElapsedPlaybackTime] = CMTimeGetSeconds(currentItem.currentTime())
        nowPlayingInfo[MPMediaItemPropertyPlaybackDuration] = CMTimeGetSeconds(currentItem.asset.duration)
        nowPlayingInfo[MPNowPlayingInfoPropertyPlaybackRate] = player?.rate

        nowPlayingInfoCenter.nowPlayingInfo = nowPlayingInfo
    }
    
    private func startVolumeMonitoring() {
        timer?.invalidate()
        timer = Timer.scheduledTimer(timeInterval: 0.1, target: self, selector: #selector(updateVolume), userInfo: nil, repeats: true)
    }
    
    @objc private func updateVolume() {
        guard let currentItem = player?.currentItem else { return }
        let asset = currentItem.asset
        asset.loadValuesAsynchronously(forKeys: ["tracks"]) {
            var error: NSError?
            let status = asset.statusOfValue(forKey: "tracks", error: &error)
            if status == .loaded {
                if let track = asset.tracks(withMediaType: .audio).first {
                    let formatDescriptions = track.formatDescriptions as! [CMAudioFormatDescription]
                    if let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescriptions[0]) {
                        let sampleRate = audioStreamBasicDescription.pointee.mSampleRate
                        let channelCount = audioStreamBasicDescription.pointee.mChannelsPerFrame
                        let bufferSize = UInt32(sampleRate * 0.1)
                        
                        var buffer = [Int16](repeating: 0, count: Int(bufferSize))
                        var bufferList = AudioBufferList()
                        bufferList.mNumberBuffers = 1
                        bufferList.mBuffers.mNumberChannels = channelCount
                        bufferList.mBuffers.mDataByteSize = bufferSize * 2
                        bufferList.mBuffers.mData = &buffer
                        
                        if let audioUnit = track.copy() as? AVAudioUnit {
                            audioUnit.inputHandler = { (bufferList, _) in
                                let buffer = bufferList[0]
                                let samples = buffer.mData?.assumingMemoryBound(to: Int16.self)
                                let sampleCount = Int(buffer.mDataByteSize) / MemoryLayout<Int16>.size
                                
                                var sum: Float = 0.0
                                for i in 0..<sampleCount {
                                    sum += abs(Float(samples?[i] ?? 0))
                                }
                                
                                let avgVolume = sum / Float(sampleCount)
                                DispatchQueue.main.async {
                                    self.currentVolume = avgVolume
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}
```

### 2. SwiftUI Viewの実装

次に、SwiftUIビューを作成して、音量を表示します。

```swift
import SwiftUI

struct ContentView: View {
    @ObservedObject var audioPlayerManager = AudioPlayerManager.shared

    var body: some View {
        VStack {
            Text("Audio Player")
                .font(.largeTitle)
                .padding()
            
            Text("Current Volume: \(audioPlayerManager.currentVolume, specifier: "%.2f")")
                .padding()
            
            Button(action: {
                audioPlayerManager.play()
            }) {
                Text("Play")
                    .padding()
                    .background(Color.blue)
                    .foregroundColor(.white)
                    .cornerRadius(8)
            }
            
            Button(action: {
                audioPlayerManager.pause()
            }) {
                Text("Pause")
                    .padding()
                    .background(Color.red)
                    .foregroundColor(.white)
                    .cornerRadius(8)
            }
        }
    }
}

@main
struct YourApp: App {
    var body: some Scene {
        WindowGroup {
            ContentView()
        }
    }
}
```

### 説明
- `AudioPlayerManager`クラスを拡張し、音量を取得するロジックを追加しました。`currentVolume`プロパティは、SwiftUIのビューにバインドされます。
- `startVolumeMonitoring`メソッドで、タイマーを使って定期的に音量を取得し、`updateVolume`メソッドで現在の音量を更新します。
- SwiftUIの`ContentView`で、`AudioPlayerManager`を`@ObservedObject`として監視し、音量を表示します。

この実装により、音量のリアルタイム表示が可能になり、ユーザーが視覚的に確認できるようになります。

---
