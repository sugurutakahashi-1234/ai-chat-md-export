# Visualize SwiftUI Sound Wave.

æ—¥ä»˜: 2024-06-19

---

## ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼
*2024/6/19 10:48:01*

{
  "content\_type": "image\_asset\_pointer",
  "asset\_pointer": "file-service://file-j3rUoiWyQuDMcB5ZG7LuWGvi",
  "size\_bytes": 142821,
  "width": 1156,
  "height": 1144,
  "fovea": null,
  "metadata": {
    "dalle": null,
    "gizmo": null,
    "generation": null,
    "container\_pixel\_height": null,
    "container\_pixel\_width": null,
    "emu\_omit\_glimpse\_image": null,
    "emu\_patches\_override": null,
    "sanitized": true,
    "asset\_pointer\_link": null,
    "watermarked\_asset\_pointer": null
  }
}
SwiftUIã§éŸ³å£°å†ç”Ÿæ™‚ã«éŸ³é‡ãªã©ã‚’è¡¨ã™ç°¡æ˜“çš„ãªæ³¢å½¢ã‚’è¡¨ç¾ã—ãŸã„ã€‚æ­£ç¢ºã§ã¯ãªãã¦è‰¯ã„ã®ã ãŒã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒ¡ã•ã‚ŒãŸæ³¢å½¢ã‚’è¡¨ç¾ã—ãŸã„ã€‚ã‚¤ãƒ¡ãƒ¼ã‚¸ã¨ã—ã¦ã¯ã“ã‚“ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã‚ã‚‹ã€‚

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2024/6/19 10:48:18*

SwiftUIã§éŸ³å£°å†ç”Ÿæ™‚ã«éŸ³é‡ã‚’è¡¨ã™ç°¡æ˜“çš„ãªæ³¢å½¢ã‚’è¡¨ç¾ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ–¹æ³•ã§ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã§ãã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒ¡ã•ã‚ŒãŸæ³¢å½¢ã‚’è¡¨ç¾ã™ã‚‹ãŸã‚ã«ã€ãƒ©ãƒ³ãƒ€ãƒ ãªé«˜ã•ã®é•·æ–¹å½¢ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```swift
import SwiftUI

struct WaveformView: View {
    @State private var heights: [CGFloat] = [20, 40, 60, 80, 60, 40, 20]
    
    var body: some View {
        HStack(alignment: .bottom, spacing: 4) {
            ForEach(0..<heights.count, id: \.self) { index in
                Rectangle()
                    .fill(Color.black)
                    .frame(width: 10, height: heights[index])
            }
        }
        .onAppear {
            Timer.scheduledTimer(withTimeInterval: 0.2, repeats: true) { _ in
                withAnimation {
                    heights = heights.map { _ in CGFloat.random(in: 20...80) }
                }
            }
        }
    }
}

struct ContentView: View {
    var body: some View {
        VStack {
            Text("éŸ³å£°æ³¢å½¢è¡¨ç¤º")
                .font(.headline)
            WaveformView()
                .frame(height: 100)
        }
        .padding()
    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}
```

### èª¬æ˜
1. **WaveformView**:
    - é•·æ–¹å½¢ã®é«˜ã•ã‚’ä¿æŒã™ã‚‹`heights`é…åˆ—ã‚’æŒã£ã¦ã„ã¾ã™ã€‚
    - `HStack`ã‚’ä½¿ç”¨ã—ã¦é•·æ–¹å½¢ã‚’ä¸¦ã¹ã¾ã™ã€‚
    - `onAppear`ã§`Timer`ã‚’è¨­å®šã—ã€å®šæœŸçš„ã«é•·æ–¹å½¢ã®é«˜ã•ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰æ›´ã—ã¦ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚

2. **ContentView**:
    - ã‚¿ã‚¤ãƒˆãƒ«ã¨`WaveformView`ã‚’`VStack`ã§é…ç½®ã—ã¾ã™ã€‚
    - `WaveformView`ã®é«˜ã•ã‚’è¨­å®šã—ã¾ã™ã€‚

ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã†ã¨ã€éŸ³å£°å†ç”Ÿä¸­ã«æ³¢å½¢ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒ¡ã—ã¦è¡¨ç¤ºã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚æ³¢å½¢ã®å‹•ãã¯éŸ³å£°ã®ãƒªã‚¢ãƒ«ãªæ³¢å½¢ã‚’è¡¨ã—ã¦ã„ã¾ã›ã‚“ãŒã€è¦–è¦šçš„ãªåŠ¹æœã¨ã—ã¦ååˆ†ã§ã™ã€‚

---

## ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼
*2024/6/19 10:48:54*

å®Ÿéš›ã®éŸ³é‡ãªã©é©å½“ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’å–å¾—ã—ã¦æ£’ã‚’é«˜ãã—ãŸã‚Šä½ãã—ãŸã‚Šã—ãŸã„ã€‚

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2024/6/19 10:49:12*

å®Ÿéš›ã®éŸ³é‡ã«åŸºã¥ã„ã¦æ³¢å½¢ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€AVFoundationã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚¯å…¥åŠ›ã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã§ã¯ã€éŸ³å£°å…¥åŠ›ã®ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ã„ã¦æ³¢å½¢ã‚’è¡¨ç¤ºã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚

ã¾ãšã€å¿…è¦ãªAVFoundationã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã€AVAudioRecorderã‚’ä½¿ã£ã¦éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—ã—ã¾ã™ã€‚

```swift
import SwiftUI
import AVFoundation

class AudioLevelMonitor: ObservableObject {
    private var audioRecorder: AVAudioRecorder!
    private var timer: Timer?
    
    @Published var levels: [CGFloat] = Array(repeating: 0, count: 20)
    
    init() {
        startMonitoring()
    }
    
    private func startMonitoring() {
        let audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth])
            try audioSession.setActive(true)
            
            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatAppleLossless),
                AVSampleRateKey: 44100.0,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.max.rawValue
            ]
            
            let url = URL(fileURLWithPath: "/dev/null")
            audioRecorder = try AVAudioRecorder(url: url, settings: settings)
            audioRecorder.isMeteringEnabled = true
            audioRecorder.record()
            
            timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                self.audioRecorder.updateMeters()
                let level = self.audioRecorder.averagePower(forChannel: 0)
                let normalizedLevel = self.normalizedPowerLevel(fromDecibels: level)
                DispatchQueue.main.async {
                    self.levels = self.levels.map { _ in CGFloat(normalizedLevel * 100) }
                }
            }
        } catch {
            print("Failed to set up audio session and recorder: \(error)")
        }
    }
    
    private func normalizedPowerLevel(fromDecibels decibels: Float) -> Float {
        let minDb: Float = -80
        if decibels < minDb {
            return 0.0
        } else if decibels >= 0.0 {
            return 1.0
        } else {
            return (abs(minDb) - abs(decibels)) / abs(minDb)
        }
    }
    
    deinit {
        timer?.invalidate()
        audioRecorder.stop()
    }
}

struct WaveformView: View {
    @ObservedObject var monitor = AudioLevelMonitor()
    
    var body: some View {
        HStack(alignment: .bottom, spacing: 4) {
            ForEach(0..<monitor.levels.count, id: \.self) { index in
                Rectangle()
                    .fill(Color.black)
                    .frame(width: 10, height: monitor.levels[index])
            }
        }
        .frame(height: 100)
    }
}

struct ContentView: View {
    var body: some View {
        VStack {
            Text("éŸ³å£°æ³¢å½¢è¡¨ç¤º")
                .font(.headline)
            WaveformView()
                .frame(height: 100)
        }
        .padding()
    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}
```

### èª¬æ˜

1. **AudioLevelMonitor**:
    - `AVAudioRecorder`ã‚’ä½¿ç”¨ã—ã¦éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—ã—ã¾ã™ã€‚
    - `Timer`ã‚’è¨­å®šã—ã€å®šæœŸçš„ã«éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ã€‚
    - ãƒ‡ã‚·ãƒ™ãƒ«å€¤ã‚’æ­£è¦åŒ–ã—ã¦æ³¢å½¢ã®é«˜ã•ã«å¤‰æ›ã—ã¾ã™ã€‚

2. **WaveformView**:
    - `AudioLevelMonitor`ã‚’ä½¿ç”¨ã—ã¦éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’ç›£è¦–ã—ã€æ³¢å½¢ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚

3. **ContentView**:
    - ã‚¿ã‚¤ãƒˆãƒ«ã¨`WaveformView`ã‚’`VStack`ã§é…ç½®ã—ã¾ã™ã€‚

ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã†ã¨ã€ãƒã‚¤ã‚¯å…¥åŠ›ã«åŸºã¥ã„ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æ³¢å½¢è¡¨ç¤ºãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

---

## ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼
*2024/6/19 10:51:08*

ã“ã‚Œã ã¨å˜ç´”ãªå¤§ãã•ã®ã¿ã‚’åæ˜ ã™ã‚‹ã®ã§ã€2æ¬¡å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§å¤‰åŒ–ã•ã›ãŸã„ã€‚

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2024/6/19 10:51:32*

2æ¬¡å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§æ³¢å½¢ã‚’å¤‰åŒ–ã•ã›ã‚‹ã«ã¯ã€éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’åæ˜ ã™ã‚‹ã ã‘ã§ãªãã€æ™‚é–“çµŒéã«ä¼´ã†å¤‰åŒ–ã‚‚å–ã‚Šå…¥ã‚Œã¾ã™ã€‚ä¾‹ãˆã°ã€æ³¢å½¢ã®è¤‡æ•°ã®æ£’ã®é«˜ã•ã‚’ã€ãã‚Œãã‚Œç•°ãªã‚‹éŸ³é‡ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ã„ã¦å‹•çš„ã«æ›´æ–°ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã§ã¯ã€è¤‡æ•°ã®æ³¢å½¢è¦ç´ ã‚’æ™‚é–“ã¨éŸ³é‡ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ã„ã¦å‹•çš„ã«å¤‰åŒ–ã•ã›ã¾ã™ã€‚

```swift
import SwiftUI
import AVFoundation

class AudioLevelMonitor: ObservableObject {
    private var audioRecorder: AVAudioRecorder!
    private var timer: Timer?
    
    @Published var levels: [CGFloat] = Array(repeating: 0, count: 20)
    
    init() {
        startMonitoring()
    }
    
    private func startMonitoring() {
        let audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth])
            try audioSession.setActive(true)
            
            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatAppleLossless),
                AVSampleRateKey: 44100.0,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.max.rawValue
            ]
            
            let url = URL(fileURLWithPath: "/dev/null")
            audioRecorder = try AVAudioRecorder(url: url, settings: settings)
            audioRecorder.isMeteringEnabled = true
            audioRecorder.record()
            
            timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                self.audioRecorder.updateMeters()
                let level = self.audioRecorder.averagePower(forChannel: 0)
                let normalizedLevel = self.normalizedPowerLevel(fromDecibels: level)
                DispatchQueue.main.async {
                    self.updateLevels(with: normalizedLevel)
                }
            }
        } catch {
            print("Failed to set up audio session and recorder: \(error)")
        }
    }
    
    private func normalizedPowerLevel(fromDecibels decibels: Float) -> Float {
        let minDb: Float = -80
        if decibels < minDb {
            return 0.0
        } else if decibels >= 0.0 {
            return 1.0
        } else {
            return (abs(minDb) - abs(decibels)) / abs(minDb)
        }
    }
    
    private func updateLevels(with newLevel: Float) {
        // Shift all levels to the left and add the new level to the end
        levels.removeFirst()
        levels.append(CGFloat(newLevel * 100))
    }
    
    deinit {
        timer?.invalidate()
        audioRecorder.stop()
    }
}

struct WaveformView: View {
    @ObservedObject var monitor = AudioLevelMonitor()
    
    var body: some View {
        HStack(alignment: .bottom, spacing: 4) {
            ForEach(0..<monitor.levels.count, id: \.self) { index in
                Rectangle()
                    .fill(Color.black)
                    .frame(width: 10, height: monitor.levels[index])
            }
        }
        .frame(height: 100)
    }
}

struct ContentView: View {
    var body: some View {
        VStack {
            Text("éŸ³å£°æ³¢å½¢è¡¨ç¤º")
                .font(.headline)
            WaveformView()
                .frame(height: 100)
        }
        .padding()
    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}
```

### èª¬æ˜

1. **AudioLevelMonitor**:
    - `AVAudioRecorder`ã‚’ä½¿ç”¨ã—ã¦éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—ã—ã¾ã™ã€‚
    - `Timer`ã‚’è¨­å®šã—ã€å®šæœŸçš„ã«éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ã€‚
    - ãƒ‡ã‚·ãƒ™ãƒ«å€¤ã‚’æ­£è¦åŒ–ã—ã¦æ³¢å½¢ã®é«˜ã•ã«å¤‰æ›ã—ã¾ã™ã€‚
    - `updateLevels`ãƒ¡ã‚½ãƒƒãƒ‰ã§ã€æœ€æ–°ã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’é…åˆ—ã®æœ€å¾Œã«è¿½åŠ ã—ã€å¤ã„å€¤ã‚’å‰Šé™¤ã—ã¦æ³¢å½¢ãŒå·¦ã‹ã‚‰å³ã«æµã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

2. **WaveformView**:
    - `AudioLevelMonitor`ã‚’ä½¿ç”¨ã—ã¦éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’ç›£è¦–ã—ã€æ³¢å½¢ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚

3. **ContentView**:
    - ã‚¿ã‚¤ãƒˆãƒ«ã¨`WaveformView`ã‚’`VStack`ã§é…ç½®ã—ã¾ã™ã€‚

ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã†ã¨ã€ãƒã‚¤ã‚¯å…¥åŠ›ã«åŸºã¥ã„ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æ³¢å½¢è¡¨ç¤ºãŒå¯èƒ½ã«ãªã‚Šã€æ³¢å½¢ãŒæ™‚é–“ã¨ã¨ã‚‚ã«å¤‰åŒ–ã—ã¦å‹•çš„ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

---

## ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼
*2024/6/19 10:51:49*

ã“ã®å ´åˆæ¨ªè»¸ã¯ä½•ã§ç¸¦è»¸ã¯ä½•ã‚’è¡¨ã™ã®ã‹ï¼Ÿ

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2024/6/19 10:51:59*

ã“ã®å ´åˆã€ç¸¦è»¸ã¨æ¨ªè»¸ã®æ„å‘³ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

- \*\*ç¸¦è»¸ (Yè»¸)\*\*: æ³¢å½¢ã®æ£’ã®é«˜ã•ã‚’è¡¨ã—ã€éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’ç¤ºã—ã¾ã™ã€‚éŸ³é‡ãŒå¤§ãã„ã»ã©æ£’ã®é«˜ã•ãŒé«˜ããªã‚Šã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€éŸ³å£°ã®ãƒ‡ã‚·ãƒ™ãƒ«ãƒ¬ãƒ™ãƒ«ã‚’æ­£è¦åŒ–ã—ãŸå€¤ã«åŸºã¥ã„ã¦é«˜ã•ãŒæ±ºã¾ã‚Šã¾ã™ã€‚

- \*\*æ¨ªè»¸ (Xè»¸)\*\*: æ™‚é–“ã®çµŒéã‚’è¡¨ã—ã¾ã™ã€‚æœ€æ–°ã®éŸ³é‡ãƒ‡ãƒ¼ã‚¿ãŒå³ç«¯ã«è¿½åŠ ã•ã‚Œã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã¯å·¦ç«¯ã«ç§»å‹•ã—ã¾ã™ã€‚ã“ã‚Œã¯æ³¢å½¢ãŒå·¦ã‹ã‚‰å³ã«æµã‚Œã¦ã„ãã‚ˆã†ã«è¦‹ãˆã‚‹åŠ¹æœã‚’ç”Ÿã¿å‡ºã—ã¾ã™ã€‚

ã“ã®ãƒ“ãƒ¥ãƒ¼ã§ã¯ã€æœ€æ–°ã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ãŒç¶™ç¶šçš„ã«è¡¨ç¤ºã•ã‚Œã€éå»ã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ãŒæ™‚é–“ã®çµŒéã¨ã¨ã‚‚ã«å·¦ã«æµã‚Œã¦ã„ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ³¢å½¢ãŒå‹•ã„ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å¤‰å‹•ã‚’è¦–è¦šåŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

---

## ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼
*2024/6/19 10:52:29*

æ™‚é–“çµŒéä»¥å¤–ã§æ¨ªè»¸ã‚’å–ã‚ŠãŸã„ã€‚ãã®ç¬é–“ã‚’è¡¨ã™ã‚ˆã†ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãŒã„ã„ã€‚

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2024/6/19 10:53:11*

æ™‚é–“çµŒéä»¥å¤–ã§æ¨ªè»¸ã‚’å–ã‚‹å ´åˆã€ä¾‹ãˆã°éŸ³å£°ã®å‘¨æ³¢æ•°æˆåˆ†ã‚’æ¨ªè»¸ã«å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å„ç¬é–“ã®å‘¨æ³¢æ•°ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ã‚’è¡¨ç¤ºã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚FFTï¼ˆFast Fourier Transformï¼‰ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ä¿¡å·ã®å‘¨æ³¢æ•°æˆåˆ†ã‚’æŠ½å‡ºã—ã€ãã®çµæœã‚’æ³¢å½¢ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

ä»¥ä¸‹ã¯ã€Swiftã®`AVAudioEngine`ã‚’ä½¿ã£ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŸ³å£°ã®å‘¨æ³¢æ•°ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ã‚’è¡¨ç¤ºã™ã‚‹ä¾‹ã§ã™ã€‚

```swift
import SwiftUI
import AVFoundation

class AudioFrequencyMonitor: ObservableObject {
    private var audioEngine: AVAudioEngine!
    private var inputNode: AVAudioInputNode!
    private var bus: Int = 0
    private let fftSize: Int = 512
    
    @Published var amplitudes: [CGFloat] = Array(repeating: 0, count: 256)
    
    init() {
        startMonitoring()
    }
    
    private func startMonitoring() {
        audioEngine = AVAudioEngine()
        inputNode = audioEngine.inputNode
        let inputFormat = inputNode.inputFormat(forBus: bus)
        
        inputNode.installTap(onBus: bus, bufferSize: AVAudioFrameCount(fftSize), format: inputFormat) { buffer, _ in
            guard let channelData = buffer.floatChannelData?[0] else { return }
            let channelDataArray = Array(UnsafeBufferPointer(start: channelData, count: Int(buffer.frameLength)))
            let fft = FFT(channelDataArray: channelDataArray, sampleRate: Float(inputFormat.sampleRate))
            let fftResults = fft.calculateFFT()
            
            DispatchQueue.main.async {
                self.amplitudes = fftResults.map { CGFloat($0) }
            }
        }
        
        audioEngine.prepare()
        do {
            try audioEngine.start()
        } catch {
            print("Audio Engine couldn't start: \(error.localizedDescription)")
        }
    }
    
    deinit {
        inputNode.removeTap(onBus: bus)
        audioEngine.stop()
    }
}

class FFT {
    private var fftSetup: FFTSetup
    private var fftSize: Int
    private var log2n: vDSP_Length
    
    init(channelDataArray: [Float], sampleRate: Float) {
        self.fftSize = channelDataArray.count
        self.log2n = vDSP_Length(log2(Float(fftSize)))
        self.fftSetup = vDSP_create_fftsetup(log2n, Int32(kFFTRadix2))!
    }
    
    func calculateFFT() -> [Float] {
        var realp = [Float](repeating: 0, count: fftSize/2)
        var imagp = [Float](repeating: 0, count: fftSize/2)
        
        realp.withUnsafeMutableBufferPointer { realPointer in
            imagp.withUnsafeMutableBufferPointer { imagPointer in
                let dspSplitComplex = DSPSplitComplex(realp: realPointer.baseAddress!, imagp: imagPointer.baseAddress!)
                var window = [Float](repeating: 0.0, count: fftSize)
                vDSP_hann_window(&window, vDSP_Length(fftSize), Int32(vDSP_HANN_NORM))
                
                var channelData = channelDataArray
                vDSP_vmul(channelData, 1, window, 1, &channelData, 1, vDSP_Length(fftSize))
                
                channelData.withUnsafeBufferPointer { pointer in
                    pointer.baseAddress!.withMemoryRebound(to: DSPComplex.self, capacity: channelDataArray.count) { typeConvertedTransferBuffer in
                        vDSP_ctoz(typeConvertedTransferBuffer, 2, &dspSplitComplex, 1, vDSP_Length(fftSize/2))
                    }
                }
                
                vDSP_fft_zrip(fftSetup, &dspSplitComplex, 1, log2n, FFTDirection(FFT_FORWARD))
                
                var magnitudes = [Float](repeating: 0.0, count: fftSize/2)
                vDSP_zvmags(&dspSplitComplex, 1, &magnitudes, 1, vDSP_Length(fftSize/2))
                
                var normalizedMagnitudes = [Float](repeating: 0.0, count: fftSize/2)
                vDSP_vsmul(sqrtf(magnitudes), 1, [2.0 / Float(fftSize)], &normalizedMagnitudes, 1, vDSP_Length(fftSize/2))
                
                return normalizedMagnitudes
            }
        }
    }
}

struct FrequencySpectrumView: View {
    @ObservedObject var monitor = AudioFrequencyMonitor()
    
    var body: some View {
        HStack(alignment: .bottom, spacing: 1) {
            ForEach(0..<monitor.amplitudes.count, id: \.self) { index in
                Rectangle()
                    .fill(Color.black)
                    .frame(width: 2, height: monitor.amplitudes[index] * 200)
            }
        }
        .frame(height: 200)
    }
}

struct ContentView: View {
    var body: some View {
        VStack {
            Text("éŸ³å£°ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ è¡¨ç¤º")
                .font(.headline)
            FrequencySpectrumView()
                .frame(height: 200)
        }
        .padding()
    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}
```

### èª¬æ˜

1. **AudioFrequencyMonitor**:
    - `AVAudioEngine`ã¨`AVAudioInputNode`ã‚’ä½¿ç”¨ã—ã¦ã€éŸ³å£°å…¥åŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¾ã™ã€‚
    - FFTã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€çµæœã‚’`amplitudes`é…åˆ—ã«ä¿å­˜ã—ã¾ã™ã€‚

2. **FFTã‚¯ãƒ©ã‚¹**:
    - FFTã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨è¨ˆç®—å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚
    - å…¥åŠ›ä¿¡å·ã®å‘¨æ³¢æ•°æˆåˆ†ã‚’è¨ˆç®—ã—ã€æŒ¯å¹…ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚

3. **FrequencySpectrumView**:
    - `AudioFrequencyMonitor`ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å‘¨æ³¢æ•°ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚

4. **ContentView**:
    - ã‚¿ã‚¤ãƒˆãƒ«ã¨`FrequencySpectrumView`ã‚’`VStack`ã§é…ç½®ã—ã¾ã™ã€‚

ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã†ã¨ã€éŸ³å£°å…¥åŠ›ã®å‘¨æ³¢æ•°æˆåˆ†ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¦–è¦šåŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¨ªè»¸ãŒå‘¨æ³¢æ•°ã€ç¸¦è»¸ãŒãã®å‘¨æ³¢æ•°æˆåˆ†ã®æŒ¯å¹…ã‚’è¡¨ã—ã¾ã™ã€‚

---
