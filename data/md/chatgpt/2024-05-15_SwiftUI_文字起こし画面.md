# SwiftUI 文字起こし画面

日付: 2024-05-15

---

## 👤 ユーザー
*2024/05/15 14:32:32*

SwiftUIのTranscriptionViewでaudioUrl: URLを引数で渡して、文字起こしする画面を以下のコードで作成してほしい。

import WhisperKit

import SwiftUI

struct TranscriptionView: View {
    
}

final class TranscriptionDriver {
    func transcribe(audioUrl: URL) async throws -&gt; [TranscriptionResult] {
        let whisper = try await WhisperKit()
        return try await whisper.transcribe(audioPath: audioUrl.path,decodeOptions:DecodingOptions.init(language: "ja"))
    }
}

---

## 🤖 アシスタント
*2024/05/15 14:32:40*

以下のコードは、SwiftUIを使用してTranscriptionViewを作成し、音声ファイルのURLを受け取り、その文字起こしを行う画面です。`WhisperKit`を使用して音声を文字起こしする機能を持つ`TranscriptionDriver`も実装しています。

```swift
import WhisperKit
import SwiftUI

struct TranscriptionView: View {
    let audioUrl: URL
    @State private var transcriptionResults: [TranscriptionResult] = []
    @State private var isLoading: Bool = false
    @State private var errorMessage: String? = nil

    var body: some View {
        VStack {
            if isLoading {
                ProgressView("Transcribing...")
            } else if let errorMessage = errorMessage {
                Text("Error: \(errorMessage)")
                    .foregroundColor(.red)
            } else {
                List(transcriptionResults, id: \.self) { result in
                    Text(result.text)
                }
            }
        }
        .onAppear {
            Task {
                await transcribeAudio()
            }
        }
    }

    private func transcribeAudio() async {
        isLoading = true
        errorMessage = nil
        let driver = TranscriptionDriver()
        
        do {
            transcriptionResults = try await driver.transcribe(audioUrl: audioUrl)
        } catch {
            errorMessage = error.localizedDescription
        }
        isLoading = false
    }
}

final class TranscriptionDriver {
    func transcribe(audioUrl: URL) async throws -> [TranscriptionResult] {
        let whisper = try await WhisperKit()
        return try await whisper.transcribe(audioPath: audioUrl.path, decodeOptions: DecodingOptions(language: "ja"))
    }
}
```

このコードでは、`TranscriptionView`は以下のように構成されています：
- `audioUrl`というプロパティで音声ファイルのURLを受け取ります。
- `@State`プロパティを使用して、文字起こしの結果、読み込み状態、エラーメッセージを管理します。
- `body`プロパティでは、読み込み中、エラー発生時、正常に文字起こし結果を表示する場合のUIを定義しています。
- `onAppear`モディファイアを使用して、画面が表示されたときに文字起こし処理を非同期で開始します。

`TranscriptionDriver`クラスは、`WhisperKit`を使用して指定された音声ファイルを文字起こしする機能を持っています。

---

## 👤 ユーザー
*2024/05/15 14:33:06*

TranscriptionViewModelを作ってほしい

---

## 🤖 アシスタント
*2024/05/15 14:33:14*

以下は、`TranscriptionViewModel`を使用して、`TranscriptionView`のロジックをViewModelに分離するコードです。これにより、Viewとロジックの分離が実現され、テスト可能性が向上します。

```swift
import WhisperKit
import SwiftUI
import Combine

class TranscriptionViewModel: ObservableObject {
    @Published var transcriptionResults: [TranscriptionResult] = []
    @Published var isLoading: Bool = false
    @Published var errorMessage: String? = nil
    
    private var cancellables = Set<AnyCancellable>()
    private let transcriptionDriver = TranscriptionDriver()

    func transcribe(audioUrl: URL) {
        isLoading = true
        errorMessage = nil
        
        Task {
            do {
                let results = try await transcriptionDriver.transcribe(audioUrl: audioUrl)
                DispatchQueue.main.async {
                    self.transcriptionResults = results
                    self.isLoading = false
                }
            } catch {
                DispatchQueue.main.async {
                    self.errorMessage = error.localizedDescription
                    self.isLoading = false
                }
            }
        }
    }
}

struct TranscriptionView: View {
    let audioUrl: URL
    @StateObject private var viewModel = TranscriptionViewModel()

    var body: some View {
        VStack {
            if viewModel.isLoading {
                ProgressView("Transcribing...")
            } else if let errorMessage = viewModel.errorMessage {
                Text("Error: \(errorMessage)")
                    .foregroundColor(.red)
            } else {
                List(viewModel.transcriptionResults, id: \.self) { result in
                    Text(result.text)
                }
            }
        }
        .onAppear {
            viewModel.transcribe(audioUrl: audioUrl)
        }
    }
}

final class TranscriptionDriver {
    func transcribe(audioUrl: URL) async throws -> [TranscriptionResult] {
        let whisper = try await WhisperKit()
        return try await whisper.transcribe(audioPath: audioUrl.path, decodeOptions: DecodingOptions(language: "ja"))
    }
}
```

### 変更点

1. **`TranscriptionViewModel`の作成**
   - `TranscriptionViewModel`は`ObservableObject`プロトコルに準拠し、`@Published`プロパティを持つことで、状態の変化をViewに通知します。
   - `transcribe(audioUrl:)`メソッドで音声URLを受け取り、非同期で文字起こしを行います。結果やエラーをメインスレッドで更新します。

2. **`TranscriptionView`の変更**
   - `TranscriptionView`は`@StateObject`として`TranscriptionViewModel`のインスタンスを持ちます。
   - `onAppear`モディファイアでViewModelの`transcribe(audioUrl:)`メソッドを呼び出し、文字起こしを開始します。

これにより、UIのロジックがViewModelに移動し、コードの分離と可読性が向上します。

---
