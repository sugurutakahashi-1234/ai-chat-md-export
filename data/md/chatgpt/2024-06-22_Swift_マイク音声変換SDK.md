# Swift ãƒã‚¤ã‚¯éŸ³å£°å¤‰æ›SDK

æ—¥ä»˜: 2024-06-22

---

## ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼
*2024/6/22 16:53:26*

Swiftã§ãƒã‚¤ã‚¯ã®éŸ³å£°å¤‰æ›SDKã¨ã‹ã‚ã‚Œã°æ•™ãˆã¦ã»ã—ã„

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2024/6/22 16:53:50*

Swiftã§åˆ©ç”¨å¯èƒ½ãªãƒã‚¤ã‚¯ã®éŸ³å£°å¤‰æ›SDKã«ã¯ã„ãã¤ã‹ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã«ã„ãã¤ã‹ã®ä»£è¡¨çš„ãªã‚‚ã®ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

### 1. Apple Speech Framework
AppleãŒæä¾›ã™ã‚‹çµ„ã¿è¾¼ã¿ã®éŸ³å£°èªè­˜ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- **ãƒ¡ãƒªãƒƒãƒˆ**: Appleè£½å“ã¨ã®äº’æ›æ€§ãŒé«˜ãã€ç°¡å˜ã«åˆ©ç”¨ã§ãã‚‹ã€‚
- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: ä»–ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«æ¯”ã¹ã¦æ©Ÿèƒ½ãŒé™å®šã•ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚‹ã€‚

#### ä½¿ã„æ–¹ã®ä¾‹
```swift
import Speech

class SpeechRecognizer {
    private let speechRecognizer = SFSpeechRecognizer()
    private let audioEngine = AVAudioEngine()
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?

    func startRecording() {
        let node = audioEngine.inputNode
        let recordingFormat = node.outputFormat(forBus: 0)
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()

        node.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { (buffer, _) in
            self.recognitionRequest?.append(buffer)
        }

        audioEngine.prepare()
        try? audioEngine.start()

        recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest!, resultHandler: { (result, error) in
            if let result = result {
                let transcription = result.bestTranscription.formattedString
                print(transcription)
            }
        })
    }

    func stopRecording() {
        audioEngine.stop()
        recognitionRequest?.endAudio()
        recognitionTask?.cancel()
    }
}
```

### 2. Google Cloud Speech-to-Text
Google CloudãŒæä¾›ã™ã‚‹éŸ³å£°èªè­˜APIã§ã™ã€‚å¤šè¨€èªå¯¾å¿œã—ã¦ãŠã‚Šã€é«˜ã„ç²¾åº¦ã‚’èª‡ã‚Šã¾ã™ã€‚
- **ãƒ¡ãƒªãƒƒãƒˆ**: é«˜ç²¾åº¦ãªèªè­˜ç‡ã€å¤šè¨€èªå¯¾å¿œã€‚
- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®ä¾å­˜ãŒã‚ã‚Šã€åˆ©ç”¨ã«ã¯APIã‚­ãƒ¼ãŒå¿…è¦ã€‚

#### ä½¿ã„æ–¹ã®ä¾‹
```swift
import GoogleCloudSpeechToText

let client = SpeechClient()

func transcribeAudioData(audioData: Data) {
    let recognitionConfig = RecognitionConfig(languageCode: "en-US", encoding: .linear16, sampleRateHertz: 16000)
    let recognitionAudio = RecognitionAudio(content: audioData)

    client.recognize(config: recognitionConfig, audio: recognitionAudio) { response, error in
        if let result = response?.results.first {
            let transcription = result.alternatives.first?.transcript
            print(transcription ?? "")
        }
    }
}
```

### 3. Whisper by OpenAI
Whisperã¯OpenAIãŒæä¾›ã™ã‚‹éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚å¤šè¨€èªå¯¾å¿œã—ã¦ãŠã‚Šã€ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œã—ã¾ã™ã€‚
- **ãƒ¡ãƒªãƒƒãƒˆ**: ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®å‡¦ç†ãŒå¯èƒ½ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã€‚
- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: ãƒ‡ãƒã‚¤ã‚¹ã®æ€§èƒ½ã«ä¾å­˜ã™ã‚‹å ´åˆãŒã‚ã‚‹ã€‚

#### ä½¿ã„æ–¹ã®ä¾‹
```swift
import Whisper

let whisperModel = WhisperModel()

func transcribeAudio(audioData: Data) {
    whisperModel.transcribe(audio: audioData) { result in
        switch result {
        case .success(let transcription):
            print(transcription)
        case .failure(let error):
            print(error.localizedDescription)
        }
    }
}
```

ã“ã‚Œã‚‰ã®SDKã®ä¸­ã‹ã‚‰ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶ã«æœ€ã‚‚é©ã—ãŸã‚‚ã®ã‚’é¸æŠã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚ã©ã‚Œã‚‚å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚„ã‚¬ã‚¤ãƒ‰ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã®ã§ã€ãã‚Œã«å¾“ã£ã¦å°å…¥ã‚’é€²ã‚ã¦ãã ã•ã„ã€‚

---

## ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼
*2024/6/22 16:54:31*

é•ãã¦ãƒã‚¤ã‚¯ã®å£°ã‚’ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’ã‹ã‘ã¦ãƒ¬ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ãŸã„ã‚“ã 

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2024/6/22 16:55:00*

User wants to apply effects to the microphone's audio and record it in Swift.

---

## ğŸ”§ ãƒ„ãƒ¼ãƒ«
*2024/6/22 16:55:00*

Model set context updated.

---

## ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
*2024/6/22 16:55:00*

ãƒã‚¤ã‚¯ã®éŸ³å£°ã«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’ã‹ã‘ã¦éŒ²éŸ³ã™ã‚‹ãŸã‚ã®SDKã‚„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚‚ã„ãã¤ã‹å­˜åœ¨ã—ã¾ã™ã€‚ä»¥ä¸‹ã«ã€Swiftã§åˆ©ç”¨å¯èƒ½ãªä»£è¡¨çš„ãªã‚‚ã®ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

### 1. AudioKit
AudioKitã¯å¼·åŠ›ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€éŸ³å£°ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®é©ç”¨ã‚„éŒ²éŸ³ãªã©ã€ã•ã¾ã–ã¾ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ“ä½œãŒå¯èƒ½ã§ã™ã€‚

#### AudioKitã‚’ä½¿ã£ãŸã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
```swift
import AudioKit
import AVFoundation

class AudioEffectRecorder {
    var mic: AKMicrophone!
    var reverb: AKReverb!
    var recorder: AKNodeRecorder!
    var player: AKPlayer!
    var mainMixer: AKMixer!
    
    init() {
        AKSettings.audioInputEnabled = true
        mic = AKMicrophone()
        reverb = AKReverb(mic)
        mainMixer = AKMixer(reverb)
        AudioKit.output = mainMixer
        
        do {
            try AudioKit.start()
        } catch {
            AKLog("AudioKit did not start!")
        }
        
        recorder = try? AKNodeRecorder(node: mainMixer)
    }
    
    func startRecording() {
        do {
            try recorder?.record()
        } catch {
            AKLog("Could not start recording!")
        }
    }
    
    func stopRecording() {
        recorder?.stop()
    }
    
    func playRecording() {
        if let file = recorder?.audioFile {
            player = AKPlayer(audioFile: file)
            player.play()
        }
    }
}

// ä½¿ç”¨ä¾‹
let audioEffectRecorder = AudioEffectRecorder()
audioEffectRecorder.startRecording()
// éŒ²éŸ³ä¸­ã«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆãŒé©ç”¨ã•ã‚Œã¾ã™
audioEffectRecorder.stopRecording()
audioEffectRecorder.playRecording()
```

### 2. AVFoundation
AVFoundationã‚‚ä½¿ã£ã¦ã€ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’é©ç”¨ã—ãªãŒã‚‰éŒ²éŸ³ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚AVAudioEngineã‚’ä½¿ç”¨ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’é©ç”¨ã—ã¾ã™ã€‚

#### AVFoundationã‚’ä½¿ã£ãŸã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
```swift
import AVFoundation

class AudioEffectRecorder {
    var audioEngine: AVAudioEngine!
    var inputNode: AVAudioInputNode!
    var mainMixer: AVAudioMixerNode!
    var reverb: AVAudioUnitReverb!
    var audioFile: AVAudioFile?
    
    init() {
        audioEngine = AVAudioEngine()
        inputNode = audioEngine.inputNode
        mainMixer = audioEngine.mainMixerNode
        reverb = AVAudioUnitReverb()
        
        audioEngine.attach(reverb)
        audioEngine.connect(inputNode, to: reverb, format: inputNode.inputFormat(forBus: 0))
        audioEngine.connect(reverb, to: mainMixer, format: inputNode.inputFormat(forBus: 0))
        
        reverb.loadFactoryPreset(.largeHall)
        reverb.wetDryMix = 50
        
        do {
            let documentsDirectory = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
            let fileURL = documentsDirectory.appendingPathComponent("recordedFile.caf")
            audioFile = try AVAudioFile(forWriting: fileURL, settings: inputNode.inputFormat(forBus: 0).settings)
        } catch {
            print("Failed to set up audio file: \(error)")
        }
    }
    
    func startRecording() {
        audioEngine.prepare()
        do {
            try audioEngine.start()
        } catch {
            print("AudioEngine didn't start: \(error)")
        }
        
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputNode.inputFormat(forBus: 0)) { buffer, _ in
            do {
                try self.audioFile?.write(from: buffer)
            } catch {
                print("Failed to write buffer: \(error)")
            }
        }
    }
    
    func stopRecording() {
        inputNode.removeTap(onBus: 0)
        audioEngine.stop()
    }
}

// ä½¿ç”¨ä¾‹
let audioEffectRecorder = AudioEffectRecorder()
audioEffectRecorder.startRecording()
// éŒ²éŸ³ä¸­ã«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆãŒé©ç”¨ã•ã‚Œã¾ã™
audioEffectRecorder.stopRecording()
```

ã“ã‚Œã‚‰ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã£ã¦ã€ãƒã‚¤ã‚¯ã®éŸ³å£°ã«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’ã‹ã‘ã¦éŒ²éŸ³ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶ã«åˆã‚ã›ã¦ã€é©åˆ‡ãªã‚‚ã®ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚

---
