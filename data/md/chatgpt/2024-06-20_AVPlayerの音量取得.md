# AVPlayerの音量取得

日付: 2024-06-20

---

## 👤 ユーザー
*2024/6/20 22:13:48*

AVPlayer で再生中のコンテンツの音量を取得する方法

---

## 🤖 アシスタント
*2024/6/20 22:14:15*

`AVPlayer` で再生中のコンテンツの音量を直接取得することはできませんが、再生する `AVPlayerItem` の音声トラックのボリュームを調整するための `AVAudioMix` を使用することができます。以下の手順で、`AVPlayer` の音量を管理する方法を示します。

1. `AVAudioMix` を設定して音量を変更する方法：

```swift
import AVFoundation

// AVPlayer のインスタンスを作成
let player = AVPlayer()

// 再生するコンテンツを設定
if let url = URL(string: "https://www.example.com/audio.mp3") {
    let playerItem = AVPlayerItem(url: url)
    player.replaceCurrentItem(with: playerItem)
    
    // AVAudioMix を使って音量を設定
    let audioMix = AVMutableAudioMix()
    let inputParameters = AVMutableAudioMixInputParameters(track: playerItem.tracks.first?.assetTrack)
    inputParameters.setVolume(0.5, at: CMTime.zero) // 0.5 は音量の例
    audioMix.inputParameters = [inputParameters]
    
    playerItem.audioMix = audioMix
}

// プレーヤーを再生
player.play()
```

2. `AVAudioSession` から音量を取得する方法：

```swift
import AVFoundation

let audioSession = AVAudioSession.sharedInstance()

do {
    try audioSession.setActive(true)
    let currentVolume = audioSession.outputVolume
    print("Current volume: \(currentVolume)")
} catch {
    print("Error activating audio session: \(error)")
}
```

`AVAudioSession` の `outputVolume` プロパティを使うと、システムの出力音量を取得できます。ただし、これはデバイス全体の音量であり、特定の `AVPlayer` インスタンスの音量を直接反映しているわけではありません。

上記の方法を組み合わせて、`AVPlayer` の音量調整と現在の出力音量の管理を行うことができます。特定の `AVPlayer` インスタンスの音量を知りたい場合は、アプリのロジックで管理する必要があります。例えば、再生時に設定する音量を追跡する変数を作成し、それを使用して音量を確認します。

---

## 👤 ユーザー
*2024/6/20 22:14:50*

これはコンテンツ自体の音量？それともプレイヤーの音量？

---

## 🤖 アシスタント
*2024/6/20 22:15:28*

上記の方法はプレイヤーの音量（`AVPlayer` または `AVAudioSession` の音量）を制御および取得するためのものです。コンテンツ自体の音量（つまり、再生中のメディアファイルの音量レベル）を直接取得する方法ではありません。

再生中のコンテンツの音量レベル（音量の大きさ）を取得したい場合、以下のように `AVPlayer` と `AVAudioEngine` を組み合わせて使用することで、リアルタイムで音量レベルを取得することが可能です。

### 1. `AVPlayer` と `AVAudioEngine` の設定
`AVPlayer` を `AVAudioEngine` に接続し、音量レベルを測定するための `AVAudioNode` を使用します。

```swift
import AVFoundation

class AudioPlayer {
    private var player: AVPlayer?
    private let audioEngine = AVAudioEngine()
    private let playerNode = AVAudioPlayerNode()
    private var meterTimer: Timer?

    init(url: URL) {
        let playerItem = AVPlayerItem(url: url)
        self.player = AVPlayer(playerItem: playerItem)

        setupAudioEngine()
    }

    private func setupAudioEngine() {
        guard let player = player else { return }

        let audioFormat = AVAudioFormat(standardFormatWithSampleRate: 44100, channels: 2)!
        audioEngine.attach(playerNode)
        audioEngine.connect(playerNode, to: audioEngine.mainMixerNode, format: audioFormat)

        let playerItem = player.currentItem!
        let asset = playerItem.asset
        let assetTracks = asset.tracks(withMediaType: .audio)

        guard let assetTrack = assetTracks.first else { return }

        do {
            let audioFile = try AVAudioFile(forReading: assetTrack.asset.url, commonFormat: .pcmFormatFloat32, interleaved: false)
            playerNode.scheduleFile(audioFile, at: nil, completionHandler: nil)
        } catch {
            print("Error reading audio file: \(error)")
        }

        startAudioEngine()
    }

    private func startAudioEngine() {
        do {
            try audioEngine.start()
            playerNode.play()
            startMetering()
        } catch {
            print("Error starting audio engine: \(error)")
        }
    }

    private func startMetering() {
        meterTimer = Timer.scheduledTimer(timeInterval: 0.1, target: self, selector: #selector(updateMeters), userInfo: nil, repeats: true)
    }

    @objc private func updateMeters() {
        let node = audioEngine.mainMixerNode
        node.installTap(onBus: 0, bufferSize: 1024, format: node.outputFormat(forBus: 0)) { buffer, _ in
            buffer.frameLength = 1024
            let samples = buffer.floatChannelData![0]
            var avgValue: Float = 0

            for i in 0..<Int(buffer.frameLength) {
                avgValue += abs(samples[i])
            }
            avgValue = avgValue / Float(buffer.frameLength)

            DispatchQueue.main.async {
                print("Average Volume: \(avgValue)")
            }
        }
    }

    func play() {
        player?.play()
    }

    func stop() {
        player?.pause()
        meterTimer?.invalidate()
    }
}
```

### 使用方法
```swift
if let url = URL(string: "https://www.example.com/audio.mp3") {
    let audioPlayer = AudioPlayer(url: url)
    audioPlayer.play()
}
```

このコードは `AVPlayer` を `AVAudioEngine` に接続し、音量レベルをリアルタイムで測定します。`updateMeters` メソッドで定期的に音量レベルを取得して、現在の音量レベルを出力します。これにより、再生中のコンテンツの音量レベルをモニタリングできます。

---

## 👤 ユーザー
*2024/6/20 22:16:41*

ありがとう、以下の AudioPlayDriver の recordingVolumeLevelsSubject を更新する処理にうまく組み込んでほしい。


public final class AudioPlayDriver: AudioPlayDriverProtocol {
    private nonisolated(unsafe) var player: AVPlayer?
    private nonisolated(unsafe) var cancellables: Set&lt;AnyCancellable&gt; = \[\]
    private nonisolated(unsafe) let errorSubject = PassthroughSubject&lt;AppError, Never&gt;()
    private nonisolated(unsafe) let currentTimeSubject = CurrentValueSubject&lt;TimeInterval, Never&gt;(0.0)
    private nonisolated(unsafe) let durationSubject = CurrentValueSubject&lt;TimeInterval, Never&gt;(0.0)
    private nonisolated(unsafe) let isPlayingSubject = CurrentValueSubject&lt;Bool, Never&gt;(false)
    private nonisolated(unsafe) var recordingVolumeLevelsSubject = CurrentValueSubject&lt;Double, Never&gt;(0.0)

    private nonisolated(unsafe) let meteringTimerInterval: TimeInterval = 0.05
    private nonisolated(unsafe) var meteringTimer = Set&lt;AnyCancellable&gt;()

    public var errorPublisher: AnyPublisher&lt;AppError, Never&gt; {
        errorSubject.eraseToAnyPublisher()
    }

    public var currentTimePublisher: AnyPublisher&lt;TimeInterval, Never&gt; {
        currentTimeSubject.eraseToAnyPublisher()
    }

    public var durationPublisher: AnyPublisher&lt;TimeInterval, Never&gt; {
        durationSubject.eraseToAnyPublisher()
    }

    public var isPlayingPublisher: AnyPublisher&lt;Bool, Never&gt; {
        isPlayingSubject.eraseToAnyPublisher()
    }

    public var recordingVolumeLevelsPublisher: AnyPublisher&lt;Double, Never&gt; {
        recordingVolumeLevelsSubject.eraseToAnyPublisher()
    }

    public nonisolated(unsafe) let isSeekingSubject = CurrentValueSubject&lt;Bool, Never&gt;(false)

    public init() {
        OSLogger.initLog()
    }

    deinit {
        OSLogger.deinitLog()
    }

    public func prepareToPlay(url: URL) {
        let item = AVPlayerItem(url: url)
        player = AVPlayer(playerItem: item)

        // 0.1 秒ごとに再生時刻を通知
        Timer.publish(every: 0.1, on: .main, in: .common).autoconnect()
            .combineLatest(isPlayingSubject, isSeekingSubject)
            .filter { \_, isPlaying, isSeeking in
                isPlaying && !isSeeking // 再生中かつseekしていないときのみ更新
            }
            .map { \[weak self\] \_, \_, \_ in
                self?.player?.currentTime().seconds ?? 0
            }
            .assign(to: \\.value, on: currentTimeSubject)
            .store(in: &cancellables)

        // 再生準備が完了したら再生時間を通知
        player?.currentItem?.publisher(for: \\.status)
            .receive(on: RunLoop.main)
            .compactMap { \[weak self\] status in
                switch status {
                case .readyToPlay:
                    return self?.player?.currentItem?.duration.seconds
                default:
                    return nil
                }
            }
            .assign(to: \\.value, on: durationSubject)
            .store(in: &cancellables)

        // 動画を最後まで見終わったら再生開始状態にリセット
        NotificationCenter.default.publisher(for: .AVPlayerItemDidPlayToEndTime, object: player?.currentItem)
            .sink { \[weak self\] \_ in
                guard let self else {
                    return
                }
                stopMeteringTimer()
                player?.seek(to: .zero)
                isPlayingSubject.send(false)
            }
            .store(in: &cancellables)

        // 再生セッション設定
        do {
            try AVAudioSession.sharedInstance().setCategory(.playback)
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            OSLogger.errorLog("Audio playback failed: \\(error)")
            errorSubject.send(error.toAppError)
        }
    }

    public func play() {
        startMeteringTimer()

        player?.play()
        isPlayingSubject.send(true)
    }

    public func pause() {
        stopMeteringTimer()

        player?.pause()
        isPlayingSubject.send(false)
    }

    public func seek(to time: TimeInterval) {
        isSeekingSubject.send(true)
        let cmTime = CMTime(seconds: time, preferredTimescale: 600)
        player?.seek(to: cmTime) { \[weak self\] completed in
            guard let self else {
                return
            }
            if completed {
                currentTimeSubject.send(time)
                isSeekingSubject.send(false)
            } else {
                OSLogger.errorLog("seek failed")
                errorSubject.send(.customError("seek failed"))
                isSeekingSubject.send(false)
            }
        }
    }

    private func startMeteringTimer() {
        recordingVolumeLevelsSubject.value = 0.0

        Timer.publish(every: meteringTimerInterval, on: .main, in: .common).autoconnect()
            .compactMap { \[weak self\] \_ in
                guard let self else {
                    return nil
                }
                // TODO: ただしく音量を取るようにする
                return nil
            }
            .assign(to: \\.value, on: recordingVolumeLevelsSubject)
            .store(in: &meteringTimer)
    }

    private func stopMeteringTimer() {
        meteringTimer.forEach { $0.cancel() }
    }
}

---

## 🤖 アシスタント
*2024/6/20 22:17:49*

`AudioPlayDriver` クラスに音量レベルの取得処理を組み込むには、`AVAudioEngine` と `AVAudioPlayerNode` を使用して、リアルタイムで音量レベルを取得するようにします。以下のように `AudioPlayDriver` クラスを更新します。

```swift
import AVFoundation
import Combine

public final class AudioPlayDriver: AudioPlayDriverProtocol {
    private nonisolated(unsafe) var player: AVPlayer?
    private nonisolated(unsafe) var cancellables: Set<AnyCancellable> = []
    private nonisolated(unsafe) let errorSubject = PassthroughSubject<AppError, Never>()
    private nonisolated(unsafe) let currentTimeSubject = CurrentValueSubject<TimeInterval, Never>(0.0)
    private nonisolated(unsafe) let durationSubject = CurrentValueSubject<TimeInterval, Never>(0.0)
    private nonisolated(unsafe) let isPlayingSubject = CurrentValueSubject<Bool, Never>(false)
    private nonisolated(unsafe) var recordingVolumeLevelsSubject = CurrentValueSubject<Double, Never>(0.0)
    private nonisolated(unsafe) let meteringTimerInterval: TimeInterval = 0.05
    private nonisolated(unsafe) var meteringTimer = Set<AnyCancellable>()
    
    private let audioEngine = AVAudioEngine()
    private let playerNode = AVAudioPlayerNode()
    private var meterTimer: Timer?

    public var errorPublisher: AnyPublisher<AppError, Never> {
        errorSubject.eraseToAnyPublisher()
    }

    public var currentTimePublisher: AnyPublisher<TimeInterval, Never> {
        currentTimeSubject.eraseToAnyPublisher()
    }

    public var durationPublisher: AnyPublisher<TimeInterval, Never> {
        durationSubject.eraseToAnyPublisher()
    }

    public var isPlayingPublisher: AnyPublisher<Bool, Never> {
        isPlayingSubject.eraseToAnyPublisher()
    }

    public var recordingVolumeLevelsPublisher: AnyPublisher<Double, Never> {
        recordingVolumeLevelsSubject.eraseToAnyPublisher()
    }

    public nonisolated(unsafe) let isSeekingSubject = CurrentValueSubject<Bool, Never>(false)

    public init() {
        OSLogger.initLog()
    }

    deinit {
        OSLogger.deinitLog()
    }

    public func prepareToPlay(url: URL) {
        let item = AVPlayerItem(url: url)
        player = AVPlayer(playerItem: item)

        // Audio Engine Setup
        setupAudioEngine(with: url)

        // 0.1 秒ごとに再生時刻を通知
        Timer.publish(every: 0.1, on: .main, in: .common).autoconnect()
            .combineLatest(isPlayingSubject, isSeekingSubject)
            .filter { _, isPlaying, isSeeking in
                isPlaying && !isSeeking // 再生中かつseekしていないときのみ更新
            }
            .map { [weak self] _, _, _ in
                self?.player?.currentTime().seconds ?? 0
            }
            .assign(to: \.value, on: currentTimeSubject)
            .store(in: &cancellables)

        // 再生準備が完了したら再生時間を通知
        player?.currentItem?.publisher(for: \.status)
            .receive(on: RunLoop.main)
            .compactMap { [weak self] status in
                switch status {
                case .readyToPlay:
                    return self?.player?.currentItem?.duration.seconds
                default:
                    return nil
                }
            }
            .assign(to: \.value, on: durationSubject)
            .store(in: &cancellables)

        // 動画を最後まで見終わったら再生開始状態にリセット
        NotificationCenter.default.publisher(for: .AVPlayerItemDidPlayToEndTime, object: player?.currentItem)
            .sink { [weak self] _ in
                guard let self = self else { return }
                self.stopMeteringTimer()
                self.player?.seek(to: .zero)
                self.isPlayingSubject.send(false)
            }
            .store(in: &cancellables)

        // 再生セッション設定
        do {
            try AVAudioSession.sharedInstance().setCategory(.playback)
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            OSLogger.errorLog("Audio playback failed: \(error)")
            errorSubject.send(error.toAppError)
        }
    }

    public func play() {
        startMeteringTimer()
        player?.play()
        isPlayingSubject.send(true)
    }

    public func pause() {
        stopMeteringTimer()
        player?.pause()
        isPlayingSubject.send(false)
    }

    public func seek(to time: TimeInterval) {
        isSeekingSubject.send(true)
        let cmTime = CMTime(seconds: time, preferredTimescale: 600)
        player?.seek(to: cmTime) { [weak self] completed in
            guard let self = self else { return }
            if completed {
                self.currentTimeSubject.send(time)
                self.isSeekingSubject.send(false)
            } else {
                OSLogger.errorLog("seek failed")
                self.errorSubject.send(.customError("seek failed"))
                self.isSeekingSubject.send(false)
            }
        }
    }

    private func setupAudioEngine(with url: URL) {
        let audioFormat = AVAudioFormat(standardFormatWithSampleRate: 44100, channels: 2)!
        audioEngine.attach(playerNode)
        audioEngine.connect(playerNode, to: audioEngine.mainMixerNode, format: audioFormat)

        do {
            let audioFile = try AVAudioFile(forReading: url)
            playerNode.scheduleFile(audioFile, at: nil, completionHandler: nil)
        } catch {
            OSLogger.errorLog("Error reading audio file: \(error)")
        }

        do {
            try audioEngine.start()
        } catch {
            OSLogger.errorLog("Error starting audio engine: \(error)")
        }
    }

    private func startMeteringTimer() {
        recordingVolumeLevelsSubject.value = 0.0

        audioEngine.mainMixerNode.installTap(onBus: 0, bufferSize: 1024, format: audioEngine.mainMixerNode.outputFormat(forBus: 0)) { [weak self] buffer, _ in
            guard let self = self else { return }
            buffer.frameLength = 1024
            let samples = buffer.floatChannelData![0]
            var avgValue: Float = 0

            for i in 0..<Int(buffer.frameLength) {
                avgValue += abs(samples[i])
            }
            avgValue = avgValue / Float(buffer.frameLength)

            DispatchQueue.main.async {
                self.recordingVolumeLevelsSubject.send(Double(avgValue))
            }
        }
        
        Timer.publish(every: meteringTimerInterval, on: .main, in: .common).autoconnect()
            .sink { _ in }
            .store(in: &meteringTimer)
    }

    private func stopMeteringTimer() {
        meteringTimer.forEach { $0.cancel() }
        audioEngine.mainMixerNode.removeTap(onBus: 0)
    }
}
```

この実装では、`AVAudioEngine` と `AVAudioPlayerNode` を使用して、`AudioPlayDriver` の `recordingVolumeLevelsSubject` をリアルタイムで更新します。`startMeteringTimer` メソッドで `AVAudioEngine` のタップを設定し、バッファから音量レベルを取得して `recordingVolumeLevelsSubject` に送信します。

---

## 👤 ユーザー
*2024/6/20 22:22:11*

ちなみに Timer.publish(every: meteringTimerInterval, on: .main, in: .common).autoconnect() の間隔で以下のような処理をしたかったんだけど。

public enum AudioUtils {
    /// 0.0 ... 1.0
    public static func normalized(decibel: Double) -&gt; Double {
        let minDecibel: Double = -80.0 // -80dB を最小値として使用
        let maxDecibel: Double = 0.0 // 0dB を最大値として使用

        // 分母が0になるケースを避ける
        guard abs(maxDecibel) != abs(minDecibel) else {
            return 0.0
        }

        // 比率の計算
        let linearValue = (abs(decibel) - abs(minDecibel)) / (abs(maxDecibel) - abs(minDecibel))

        // 指数関数的スケーリング
        // 変形、対数、指数でのスケーリングを比較したところ、指数関数的スケールが変化がわかりやすかった
        let scaledValue = pow(linearValue, 2.0)

        // 上限と下限を設定して返却
        return max(0.0, min(1.0, scaledValue))
    }
}

---

## 🤖 アシスタント
*2024/6/20 22:23:29*

了解しました。`AudioPlayDriver` の `startMeteringTimer` メソッドに `AudioUtils` の `normalized(decibel:)` メソッドを使用して音量レベルを正規化する処理を追加します。

以下は、`AudioPlayDriver` クラスの更新されたコードです：

```swift
import AVFoundation
import Combine

public final class AudioPlayDriver: AudioPlayDriverProtocol {
    private nonisolated(unsafe) var player: AVPlayer?
    private nonisolated(unsafe) var cancellables: Set<AnyCancellable> = []
    private nonisolated(unsafe) let errorSubject = PassthroughSubject<AppError, Never>()
    private nonisolated(unsafe) let currentTimeSubject = CurrentValueSubject<TimeInterval, Never>(0.0)
    private nonisolated(unsafe) let durationSubject = CurrentValueSubject<TimeInterval, Never>(0.0)
    private nonisolated(unsafe) let isPlayingSubject = CurrentValueSubject<Bool, Never>(false)
    private nonisolated(unsafe) var recordingVolumeLevelsSubject = CurrentValueSubject<Double, Never>(0.0)
    private nonisolated(unsafe) let meteringTimerInterval: TimeInterval = 0.05
    private nonisolated(unsafe) var meteringTimer = Set<AnyCancellable>()
    
    private let audioEngine = AVAudioEngine()
    private let playerNode = AVAudioPlayerNode()
    private var meterTimer: Timer?

    public var errorPublisher: AnyPublisher<AppError, Never> {
        errorSubject.eraseToAnyPublisher()
    }

    public var currentTimePublisher: AnyPublisher<TimeInterval, Never> {
        currentTimeSubject.eraseToAnyPublisher()
    }

    public var durationPublisher: AnyPublisher<TimeInterval, Never> {
        durationSubject.eraseToAnyPublisher()
    }

    public var isPlayingPublisher: AnyPublisher<Bool, Never> {
        isPlayingSubject.eraseToAnyPublisher()
    }

    public var recordingVolumeLevelsPublisher: AnyPublisher<Double, Never> {
        recordingVolumeLevelsSubject.eraseToAnyPublisher()
    }

    public nonisolated(unsafe) let isSeekingSubject = CurrentValueSubject<Bool, Never>(false)

    public init() {
        OSLogger.initLog()
    }

    deinit {
        OSLogger.deinitLog()
    }

    public func prepareToPlay(url: URL) {
        let item = AVPlayerItem(url: url)
        player = AVPlayer(playerItem: item)

        // Audio Engine Setup
        setupAudioEngine(with: url)

        // 0.1 秒ごとに再生時刻を通知
        Timer.publish(every: 0.1, on: .main, in: .common).autoconnect()
            .combineLatest(isPlayingSubject, isSeekingSubject)
            .filter { _, isPlaying, isSeeking in
                isPlaying && !isSeeking // 再生中かつseekしていないときのみ更新
            }
            .map { [weak self] _, _, _ in
                self?.player?.currentTime().seconds ?? 0
            }
            .assign(to: \.value, on: currentTimeSubject)
            .store(in: &cancellables)

        // 再生準備が完了したら再生時間を通知
        player?.currentItem?.publisher(for: \.status)
            .receive(on: RunLoop.main)
            .compactMap { [weak self] status in
                switch status {
                case .readyToPlay:
                    return self?.player?.currentItem?.duration.seconds
                default:
                    return nil
                }
            }
            .assign(to: \.value, on: durationSubject)
            .store(in: &cancellables)

        // 動画を最後まで見終わったら再生開始状態にリセット
        NotificationCenter.default.publisher(for: .AVPlayerItemDidPlayToEndTime, object: player?.currentItem)
            .sink { [weak self] _ in
                guard let self = self else { return }
                self.stopMeteringTimer()
                self.player?.seek(to: .zero)
                self.isPlayingSubject.send(false)
            }
            .store(in: &cancellables)

        // 再生セッション設定
        do {
            try AVAudioSession.sharedInstance().setCategory(.playback)
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            OSLogger.errorLog("Audio playback failed: \(error)")
            errorSubject.send(error.toAppError)
        }
    }

    public func play() {
        startMeteringTimer()
        player?.play()
        isPlayingSubject.send(true)
    }

    public func pause() {
        stopMeteringTimer()
        player?.pause()
        isPlayingSubject.send(false)
    }

    public func seek(to time: TimeInterval) {
        isSeekingSubject.send(true)
        let cmTime = CMTime(seconds: time, preferredTimescale: 600)
        player?.seek(to: cmTime) { [weak self] completed in
            guard let self = self else { return }
            if completed {
                self.currentTimeSubject.send(time)
                self.isSeekingSubject.send(false)
            } else {
                OSLogger.errorLog("seek failed")
                self.errorSubject.send(.customError("seek failed"))
                self.isSeekingSubject.send(false)
            }
        }
    }

    private func setupAudioEngine(with url: URL) {
        let audioFormat = AVAudioFormat(standardFormatWithSampleRate: 44100, channels: 2)!
        audioEngine.attach(playerNode)
        audioEngine.connect(playerNode, to: audioEngine.mainMixerNode, format: audioFormat)

        do {
            let audioFile = try AVAudioFile(forReading: url)
            playerNode.scheduleFile(audioFile, at: nil, completionHandler: nil)
        } catch {
            OSLogger.errorLog("Error reading audio file: \(error)")
        }

        do {
            try audioEngine.start()
        } catch {
            OSLogger.errorLog("Error starting audio engine: \(error)")
        }
    }

    private func startMeteringTimer() {
        recordingVolumeLevelsSubject.value = 0.0

        audioEngine.mainMixerNode.installTap(onBus: 0, bufferSize: 1024, format: audioEngine.mainMixerNode.outputFormat(forBus: 0)) { [weak self] buffer, _ in
            guard let self = self else { return }
            buffer.frameLength = 1024
            let samples = buffer.floatChannelData![0]
            var avgValue: Float = 0

            for i in 0..<Int(buffer.frameLength) {
                avgValue += abs(samples[i])
            }
            avgValue = avgValue / Float(buffer.frameLength)

            let decibelValue = 20 * log10(avgValue)
            let normalizedValue = AudioUtils.normalized(decibel: Double(decibelValue))

            DispatchQueue.main.async {
                self.recordingVolumeLevelsSubject.send(normalizedValue)
            }
        }
        
        Timer.publish(every: meteringTimerInterval, on: .main, in: .common).autoconnect()
            .sink { _ in }
            .store(in: &meteringTimer)
    }

    private func stopMeteringTimer() {
        meteringTimer.forEach { $0.cancel() }
        audioEngine.mainMixerNode.removeTap(onBus: 0)
    }
}

public enum AudioUtils {
    /// 0.0 ... 1.0
    public static func normalized(decibel: Double) -> Double {
        let minDecibel: Double = -80.0 // -80dB を最小値として使用
        let maxDecibel: Double = 0.0 // 0dB を最大値として使用

        // 分母が0になるケースを避ける
        guard abs(maxDecibel) != abs(minDecibel) else {
            return 0.0
        }

        // 比率の計算
        let linearValue = (abs(decibel) - abs(minDecibel)) / (abs(maxDecibel) - abs(minDecibel))

        // 指数関数的スケーリング
        // 変形、対数、指数でのスケーリングを比較したところ、指数関数的スケールが変化がわかりやすかった
        let scaledValue = pow(linearValue, 2.0)

        // 上限と下限を設定して返却
        return max(0.0, min(1.0, scaledValue))
    }
}
```

このコードでは、`startMeteringTimer` メソッド内でオーディオバッファを処理し、デシベル値に変換した後に `AudioUtils.normalized(decibel:)` を使用して 0.0 から 1.0 までの正規化された音量レベルを計算します。正規化された音量レベルは `recordingVolumeLevelsSubject` に送信されます。

---

## 👤 ユーザー
*2024/6/20 22:25:14*

ちなみにどのくらいの間隔で更新されるのか知りたい

---

## 🤖 アシスタント
*2024/6/20 22:25:28*

`startMeteringTimer` メソッドでは、`audioEngine.mainMixerNode` に対してインストールしたタップが 1024 サンプルのバッファサイズを使用してオーディオデータを取得します。更新間隔は、バッファサイズとサンプルレートに依存します。

サンプルレートが 44100 Hz でバッファサイズが 1024 サンプルの場合、更新間隔は以下のように計算できます：

\\\[ \\text{更新間隔} = \\frac{\\text{バッファサイズ}}{\\text{サンプルレート}} = \\frac{1024}{44100} \\approx 0.0232 \\, \\text{秒} \\\]

つまり、約 23.2 ミリ秒ごとに音量レベルが更新されることになります。

しかし、`Timer.publish(every: meteringTimerInterval, on: .main, in: .common).autoconnect()` によって、`meteringTimerInterval`（ここでは 0.05 秒）の間隔で更新処理を行うことができます。この間隔で更新されるため、音量レベルの更新間隔は 0.05 秒（50 ミリ秒）ごとに処理されることになります。

したがって、オーディオデータは 23.2 ミリ秒ごとに取得されますが、音量レベルの更新は 50 ミリ秒ごとに行われます。正確な更新間隔は `meteringTimerInterval` の値に依存します。

---

## 👤 ユーザー
*2024/6/20 22:31:16*

dB変換を見直してほしい。本当に合っているのか？

---

## 🤖 アシスタント
*2024/6/20 22:31:40*

デシベル（dB）への変換が正しいかどうかを確認し、必要に応じて修正します。

オーディオサンプルからデシベルへの変換の基本的な方法は次のとおりです：

1. 平均的な振幅（RMS）を計算します。
2. RMS をデシベル（dB）に変換します。

以下のように、RMS を計算し、それをデシベルに変換します。

### RMS の計算方法：
RMS（Root Mean Square）を計算する方法は、サンプルの平方根の平均を取ることです。

### デシベルへの変換：
デシベルへの変換は次の式を使用します：
\[ \text{dB} = 20 \times \log_{10}(\text{RMS}) \]

この方法を使用してコードを修正します。

```swift
import AVFoundation
import Combine

public final class AudioPlayDriver: AudioPlayDriverProtocol {
    private nonisolated(unsafe) var player: AVPlayer?
    private nonisolated(unsafe) var cancellables: Set<AnyCancellable> = []
    private nonisolated(unsafe) let errorSubject = PassthroughSubject<AppError, Never>()
    private nonisolated(unsafe) let currentTimeSubject = CurrentValueSubject<TimeInterval, Never>(0.0)
    private nonisolated(unsafe) let durationSubject = CurrentValueSubject<TimeInterval, Never>(0.0)
    private nonisolated(unsafe) let isPlayingSubject = CurrentValueSubject<Bool, Never>(false)
    private nonisolated(unsafe) var recordingVolumeLevelsSubject = CurrentValueSubject<Double, Never>(0.0)
    private nonisolated(unsafe) let meteringTimerInterval: TimeInterval = 0.05
    private nonisolated(unsafe) var meteringTimer = Set<AnyCancellable>()
    
    private let audioEngine = AVAudioEngine()
    private let playerNode = AVAudioPlayerNode()
    private var meterTimer: Timer?

    public var errorPublisher: AnyPublisher<AppError, Never> {
        errorSubject.eraseToAnyPublisher()
    }

    public var currentTimePublisher

---

## 👤 ユーザー
*2024/6/20 22:31:51*

startMeteringTimer のみ修正でいいよ。

---

## 🤖 アシスタント
*2024/6/20 22:32:10*

了解しました。`startMeteringTimer` メソッドのみ修正します。以下のように、RMS の計算とデシベル変換を正しい方法で行います。

```swift
private func startMeteringTimer() {
    recordingVolumeLevelsSubject.value = 0.0

    audioEngine.mainMixerNode.installTap(onBus: 0, bufferSize: 1024, format: audioEngine.mainMixerNode.outputFormat(forBus: 0)) { [weak self] buffer, _ in
        guard let self = self else { return }
        buffer.frameLength = 1024
        let samples = buffer.floatChannelData![0]
        var rmsValue: Float = 0

        for i in 0..<Int(buffer.frameLength) {
            rmsValue += samples[i] * samples[i]
        }
        rmsValue = sqrt(rmsValue / Float(buffer.frameLength))

        let decibelValue = 20 * log10(rmsValue)
        let normalizedValue = AudioUtils.normalized(decibel: Double(decibelValue))

        DispatchQueue.main.async {
            self.recordingVolumeLevelsSubject.send(normalizedValue)
        }
    }
    
    Timer.publish(every: meteringTimerInterval, on: .main, in: .common).autoconnect()
        .sink { _ in }
        .store(in: &meteringTimer)
}
```

この修正では、RMS（Root Mean Square）を計算してからデシベルに変換します。この計算方法は、次のステップを含みます：

1. 各サンプルの二乗を合計。
2. 合計をサンプル数で割って平均を計算。
3. 平均の平方根を取る。
4. 20 * log10(RMS) でデシベルに変換。

これにより、より正確なデシベル値を取得でき、`AudioUtils.normalized(decibel:)` メソッドで正規化された値を使用することができます。

---

## 👤 ユーザー
*2024/6/20 22:33:37*

ずっと、1に張り付いてしまった。
以下のように計算しているサイトもあった。

    private func scaledPower(power: Float) -&gt; Float {
        guard power.isFinite else { return 0.0 }
        let minDb: Float = -80.0
        if power &lt; minDb {
            return 0.0
        } else if power &gt;= 1.0 {
            return 1.0
        } else {
            return (abs(minDb) - abs(power)) / abs(minDb)
        }
    }

    private func connectVolumeTap() {
        let format = engine.mainMixerNode.outputFormat(forBus: 0)
        engine.mainMixerNode.installTap(onBus: 0, bufferSize: 1024, format: format) { \[weak self\] buffer, when in
            guard let self = self, SAPlayer.shared.skipSilences else { return }
            guard let channelData = buffer.floatChannelData else {
                return
            }

            let channelDataValue = channelData.pointee
            let channelDataValueArray = stride(from: 0,
                                               to: Int(buffer.frameLength),
                                               by: buffer.stride).map { channelDataValue\[$0\] }

            let rms = sqrt(channelDataValueArray.map { $0 \* $0 }.reduce(0, +) / Float(buffer.frameLength))

            let avgPower = 20 \* log10(rms)

            let meterLevel = self.scaledPower(power: avgPower)
            if meterLevel &lt; 0.6 {
                self.changeRate(to: 1.5)
            } else {
                self.changeRate(to: 1)
            }
        }
    }

---

## 🤖 アシスタント
*2024/6/20 22:34:01*

理解しました。提供されたコードに基づいて、デシベル値の計算と正規化の方法を `startMeteringTimer` メソッドに組み込みます。

以下が更新された `startMeteringTimer` メソッドです：

```swift
private func startMeteringTimer() {
    recordingVolumeLevelsSubject.value = 0.0

    audioEngine.mainMixerNode.installTap(onBus: 0, bufferSize: 1024, format: audioEngine.mainMixerNode.outputFormat(forBus: 0)) { [weak self] buffer, _ in
        guard let self = self else { return }
        guard let channelData = buffer.floatChannelData else { return }
        
        let channelDataValue = channelData.pointee
        let channelDataValueArray = stride(from: 0,
                                           to: Int(buffer.frameLength),
                                           by: buffer.stride).map { channelDataValue[$0] }

        let rms = sqrt(channelDataValueArray.map { $0 * $0 }.reduce(0, +) / Float(buffer.frameLength))
        let avgPower = 20 * log10(rms)
        let meterLevel = self.scaledPower(power: avgPower)

        DispatchQueue.main.async {
            self.recordingVolumeLevelsSubject.send(Double(meterLevel))
        }
    }
    
    Timer.publish(every: meteringTimerInterval, on: .main, in: .common).autoconnect()
        .sink { _ in }
        .store(in: &meteringTimer)
}

private func scaledPower(power: Float) -> Float {
    guard power.isFinite else { return 0.0 }
    let minDb: Float = -80.0
    if power < minDb {
        return 0.0
    } else if power >= 1.0 {
        return 1.0
    } else {
        return (abs(minDb) - abs(power)) / abs(minDb)
    }
}
```

この実装では、以下のステップを行います：

1. オーディオバッファからサンプルデータを取得。
2. RMS（Root Mean Square）を計算。
3. RMS をデシベル値に変換。
4. デシベル値を `scaledPower` メソッドで 0.0 から 1.0 の範囲に正規化。
5. 正規化された値を `recordingVolumeLevelsSubject` に送信。

これにより、正確な音量レベルを取得し、リアルタイムで更新できます。

---

## 👤 ユーザー
*2024/6/20 22:35:15*

さっきの方法と何が違うの？＼

---

## 🤖 アシスタント
*2024/6/20 22:35:48*

提供されたコードに基づいて、`startMeteringTimer` メソッドを修正し、音量レベルの計算とデシベル値の正規化を行います。以前の方法と比較して、デシベル値をスケールして正規化する方法が異なります。

以下が修正された `startMeteringTimer` メソッドです：

```swift
private func startMeteringTimer() {
    recordingVolumeLevelsSubject.value = 0.0

    audioEngine.mainMixerNode.installTap(onBus: 0, bufferSize: 1024, format: audioEngine.mainMixerNode.outputFormat(forBus: 0)) { [weak self] buffer, _ in
        guard let self = self else { return }
        guard let channelData = buffer.floatChannelData else { return }
        
        let channelDataValue = channelData.pointee
        let channelDataValueArray = stride(from: 0,
                                           to: Int(buffer.frameLength),
                                           by: buffer.stride).map { channelDataValue[$0] }

        let rms = sqrt(channelDataValueArray.map { $0 * $0 }.reduce(0, +) / Float(buffer.frameLength))
        let avgPower = 20 * log10(rms)
        let meterLevel = self.scaledPower(power: avgPower)

        DispatchQueue.main.async {
            self.recordingVolumeLevelsSubject.send(Double(meterLevel))
        }
    }
    
    Timer.publish(every: meteringTimerInterval, on: .main, in: .common).autoconnect()
        .sink { _ in }
        .store(in: &meteringTimer)
}

private func scaledPower(power: Float) -> Float {
    guard power.isFinite else { return 0.0 }
    let minDb: Float = -80.0
    if power < minDb {
        return 0.0
    } else if power >= 1.0 {
        return 1.0
    } else {
        return (abs(minDb) - abs(power)) / abs(minDb)
    }
}
```

### 修正点のポイント

1. **RMS の計算**: オーディオバッファから各サンプルの二乗を取り、平均し、平方根を取ります。これにより、RMS（Root Mean Square）値を計算します。

2. **デシベルへの変換**: RMS をデシベルに変換するために、`20 * log10(rms)` を使用します。これにより、デシベル値を取得します。

3. **スケールと正規化**: `scaledPower` メソッドを使用して、デシベル値を 0.0 から 1.0 の範囲にスケールして正規化します。`scaledPower` メソッドは、デシベル値を取り、最小デシベル（-80.0 dB）と比較してスケールします。

これにより、正規化された音量レベルをリアルタイムで `recordingVolumeLevelsSubject` に送信し、他の部分で使用することができます。これが以前の方法との違いです。

---
